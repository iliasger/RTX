{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness: (Average of overheads, moving average of routing costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%reload_ext autoreload\n",
    "from notebooks_commons import get_raw_data\n",
    "\n",
    "# The first time we want to download the data from an index (might take a while!), \n",
    "# we should put the parameter load_from_db to True. Then, we can set it to False to \n",
    "# read the saved data from the local pickle file.\n",
    "def read_data(index, load_from_db = False):\n",
    "    print \"\\nReading from index \" + index\n",
    "    pair = get_raw_data(index, load_from_db)\n",
    "    rtx_runs = pair[0]\n",
    "    data     = pair[1] \n",
    "    return rtx_runs, data\n",
    "\n",
    "\n",
    "# Here we specify the name of the index to read data from\n",
    "\n",
    "index_random_500 = \"erik-gcp-random-rtx-new\" \n",
    "index_novelty_500 = \"erik-gcp-novelty-rtx-new-fixedeval\"\n",
    "index_nsga2_500 = \"erik-gcp-nsga2-rtx-new\"\n",
    "index_mlr_500 = \"erik-gcp-mlr-rtx-new\" \n",
    "\n",
    "index_random_700 = \"ilias-random-700cars\" \n",
    "index_novelty_700 = \"erik-gcp-novelty-rtx-new-fixedeval-700\"\n",
    "index_nsga2_700 = \"erik-gcp-nsga2-700cars\"\n",
    "index_mlr_700 = \"ilias-mlr-700cars\" \n",
    "\n",
    "index_random_800 = \"ilias-random-800cars\" \n",
    "index_novelty_800 = \"erik-gcp-novelty-rtx-new-fixedeval-800\"\n",
    "index_nsga2_800 = \"erik-gcp-nsga2-800cars\"\n",
    "index_mlr_800 = \"ilias-mlr-800cars\" \n",
    "\n",
    "### Get Novelty data\n",
    "novelty_rtx_runs_500, novelty_data_500 = read_data(index_novelty_500)\n",
    "novelty_rtx_runs_700, novelty_data_700 = read_data(index_novelty_700)\n",
    "novelty_rtx_runs_800, novelty_data_800 = read_data(index_novelty_800)\n",
    "\n",
    "### Get NSGA2 data\n",
    "nsga2_rtx_runs_500, nsga2_data_500 = read_data(index_nsga2_500)\n",
    "nsga2_rtx_runs_700, nsga2_data_700 = read_data(index_nsga2_700)\n",
    "nsga2_rtx_runs_800, nsga2_data_800 = read_data(index_nsga2_800)\n",
    "\n",
    "### Get MLR data\n",
    "mlr_rtx_runs_500, mlr_data_500 = read_data(index_mlr_500)\n",
    "mlr_rtx_runs_700, mlr_data_700 = read_data(index_mlr_700)\n",
    "mlr_rtx_runs_800, mlr_data_800 = read_data(index_mlr_800)\n",
    "\n",
    "### Get RandomSearch data\n",
    "random_rtx_runs_500, random_data_500 = read_data(index_random_500)\n",
    "random_rtx_runs_700, random_data_700 = read_data(index_random_700)\n",
    "random_rtx_runs_800, random_data_800 = read_data(index_random_800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what's in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string, color=None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "    \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def check_data(rtx_runs, data):\n",
    "    # sort according to seed \n",
    "    rtx_runs.sort(key=lambda d : d[\"seed\"])\n",
    "    if len(rtx_runs) > 0:\n",
    "        try:\n",
    "            opt_method = rtx_runs[0][\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"MLR\"\n",
    "    print \"There were \" + str(len(rtx_runs)) + \" runs performed by \" + opt_method\n",
    "\n",
    "    for rtx_run in rtx_runs:\n",
    "        data_for_run = [d for d in data if d[\"parent\"] == rtx_run[\"id\"]]\n",
    "        data_for_run.sort(key=lambda d : (d[\"_source\"][\"iteration\"], d[\"_source\"][\"individual\"]))\n",
    "        printmd(str(len(data_for_run)) + \"\\t\\t| seed \" + str(rtx_run[\"seed\"]) \n",
    "                + \" | id \" + str(rtx_run[\"id\"]), \"red\")\n",
    "\n",
    "        #for d in data_for_run:\n",
    "        #    s = d[\"_source\"]\n",
    "        #    overheads = s[\"payload\"][\"overheads\"]\n",
    "        #    routings = s[\"payload\"][\"routings\"]\n",
    "        #    printmd(\"Iteration \" + str(s[\"iteration\"]) + \", individual \" \n",
    "        #            + str(s[\"individual\"]) + \" with configuration\", \"blue\")        \n",
    "        #    pp.pprint(s[\"knobs\"])\n",
    "        #    printmd(\"has \" + str(len(overheads)) + \" overheads and \" \n",
    "        #            + str(len(routings)) + \" routings\", \"green\")\n",
    "\n",
    "\n",
    "# random search\n",
    "check_data(random_rtx_runs_500, random_data_500)\n",
    "check_data(random_rtx_runs_700, random_data_700)\n",
    "check_data(random_rtx_runs_800, random_data_800)\n",
    "    \n",
    "# mlr\n",
    "check_data(mlr_rtx_runs_500, mlr_data_500)\n",
    "check_data(mlr_rtx_runs_700, mlr_data_700) \n",
    "check_data(mlr_rtx_runs_800, mlr_data_800)\n",
    "    \n",
    "# novelty\n",
    "check_data(novelty_rtx_runs_500, novelty_data_500)\n",
    "check_data(novelty_rtx_runs_700, novelty_data_700)\n",
    "check_data(novelty_rtx_runs_800, novelty_data_800)\n",
    "\n",
    "# nsga2\n",
    "check_data(nsga2_rtx_runs_500, nsga2_data_500)\n",
    "check_data(nsga2_rtx_runs_700, nsga2_data_700)\n",
    "check_data(nsga2_rtx_runs_800, nsga2_data_800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for computing the hypervolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    https://ls11-www.cs.tu-dortmund.de/rudolph/hypervolume/start\n",
    "\n",
    "#    Copyright (C) 2010 Simon Wessing\n",
    "#    TU Dortmund University\n",
    "#\n",
    "#    This program is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU General Public License as published by\n",
    "#    the Free Software Foundation, either version 3 of the License, or\n",
    "#    (at your option) any later version.\n",
    "#\n",
    "#    This program is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#    GNU General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU General Public License\n",
    "#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "__author__ = \"Simon Wessing\"\n",
    "\n",
    "\n",
    "class HyperVolume:\n",
    "    \"\"\"\n",
    "    Hypervolume computation based on variant 3 of the algorithm in the paper:\n",
    "    C. M. Fonseca, L. Paquete, and M. Lopez-Ibanez. An improved dimension-sweep\n",
    "    algorithm for the hypervolume indicator. In IEEE Congress on Evolutionary\n",
    "    Computation, pages 1157-1163, Vancouver, Canada, July 2006.\n",
    "\n",
    "    Minimization is implicitly assumed here!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, referencePoint):\n",
    "        \"\"\"Constructor.\"\"\"\n",
    "        self.referencePoint = referencePoint\n",
    "        self.list = []\n",
    "\n",
    "\n",
    "    def compute(self, front):\n",
    "        \"\"\"Returns the hypervolume that is dominated by a non-dominated front.\n",
    "\n",
    "        Before the HV computation, front and reference point are translated, so\n",
    "        that the reference point is [0, ..., 0].\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def weaklyDominates(point, other):\n",
    "            for i in xrange(len(point)):\n",
    "                if point[i] > other[i]:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        relevantPoints = []\n",
    "        referencePoint = self.referencePoint\n",
    "        dimensions = len(referencePoint)\n",
    "        for point in front:\n",
    "            # only consider points that dominate the reference point\n",
    "            if weaklyDominates(point, referencePoint):\n",
    "                relevantPoints.append(point)\n",
    "        if any(referencePoint):\n",
    "            # shift points so that referencePoint == [0, ..., 0]\n",
    "            # this way the reference point doesn't have to be explicitly used\n",
    "            # in the HV computation\n",
    "            for j in xrange(len(relevantPoints)):\n",
    "                relevantPoints[j] = [relevantPoints[j][i] - referencePoint[i] for i in xrange(dimensions)]\n",
    "        self.preProcess(relevantPoints)\n",
    "        bounds = [-1.0e308] * dimensions\n",
    "        hyperVolume = self.hvRecursive(dimensions - 1, len(relevantPoints), bounds)\n",
    "        return hyperVolume\n",
    "\n",
    "\n",
    "    def hvRecursive(self, dimIndex, length, bounds):\n",
    "        \"\"\"Recursive call to hypervolume calculation.\n",
    "\n",
    "        In contrast to the paper, the code assumes that the reference point\n",
    "        is [0, ..., 0]. This allows the avoidance of a few operations.\n",
    "\n",
    "        \"\"\"\n",
    "        hvol = 0.0\n",
    "        sentinel = self.list.sentinel\n",
    "        if length == 0:\n",
    "            return hvol\n",
    "        elif dimIndex == 0:\n",
    "            # special case: only one dimension\n",
    "            # why using hypervolume at all?\n",
    "            return -sentinel.next[0].cargo[0]\n",
    "        elif dimIndex == 1:\n",
    "            # special case: two dimensions, end recursion\n",
    "            q = sentinel.next[1]\n",
    "            h = q.cargo[0]\n",
    "            p = q.next[1]\n",
    "            while p is not sentinel:\n",
    "                pCargo = p.cargo\n",
    "                hvol += h * (q.cargo[1] - pCargo[1])\n",
    "                if pCargo[0] < h:\n",
    "                    h = pCargo[0]\n",
    "                q = p\n",
    "                p = q.next[1]\n",
    "            hvol += h * q.cargo[1]\n",
    "            return hvol\n",
    "        else:\n",
    "            remove = self.list.remove\n",
    "            reinsert = self.list.reinsert\n",
    "            hvRecursive = self.hvRecursive\n",
    "            p = sentinel\n",
    "            q = p.prev[dimIndex]\n",
    "            while q.cargo != None:\n",
    "                if q.ignore < dimIndex:\n",
    "                    q.ignore = 0\n",
    "                q = q.prev[dimIndex]\n",
    "            q = p.prev[dimIndex]\n",
    "            while length > 1 and (q.cargo[dimIndex] > bounds[dimIndex] or q.prev[dimIndex].cargo[dimIndex] >= bounds[dimIndex]):\n",
    "                p = q\n",
    "                remove(p, dimIndex, bounds)\n",
    "                q = p.prev[dimIndex]\n",
    "                length -= 1\n",
    "            qArea = q.area\n",
    "            qCargo = q.cargo\n",
    "            qPrevDimIndex = q.prev[dimIndex]\n",
    "            if length > 1:\n",
    "                hvol = qPrevDimIndex.volume[dimIndex] + qPrevDimIndex.area[dimIndex] * (qCargo[dimIndex] - qPrevDimIndex.cargo[dimIndex])\n",
    "            else:\n",
    "                qArea[0] = 1\n",
    "                qArea[1:dimIndex+1] = [qArea[i] * -qCargo[i] for i in xrange(dimIndex)]\n",
    "            q.volume[dimIndex] = hvol\n",
    "            if q.ignore >= dimIndex:\n",
    "                qArea[dimIndex] = qPrevDimIndex.area[dimIndex]\n",
    "            else:\n",
    "                qArea[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
    "                if qArea[dimIndex] <= qPrevDimIndex.area[dimIndex]:\n",
    "                    q.ignore = dimIndex\n",
    "            while p is not sentinel:\n",
    "                pCargoDimIndex = p.cargo[dimIndex]\n",
    "                hvol += q.area[dimIndex] * (pCargoDimIndex - q.cargo[dimIndex])\n",
    "                bounds[dimIndex] = pCargoDimIndex\n",
    "                reinsert(p, dimIndex, bounds)\n",
    "                length += 1\n",
    "                q = p\n",
    "                p = p.next[dimIndex]\n",
    "                q.volume[dimIndex] = hvol\n",
    "                if q.ignore >= dimIndex:\n",
    "                    q.area[dimIndex] = q.prev[dimIndex].area[dimIndex]\n",
    "                else:\n",
    "                    q.area[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
    "                    if q.area[dimIndex] <= q.prev[dimIndex].area[dimIndex]:\n",
    "                        q.ignore = dimIndex\n",
    "            hvol -= q.area[dimIndex] * q.cargo[dimIndex]\n",
    "            return hvol\n",
    "\n",
    "\n",
    "    def preProcess(self, front):\n",
    "        \"\"\"Sets up the list data structure needed for calculation.\"\"\"\n",
    "        dimensions = len(self.referencePoint)\n",
    "        nodeList = MultiList(dimensions)\n",
    "        nodes = [MultiList.Node(dimensions, point) for point in front]\n",
    "        for i in xrange(dimensions):\n",
    "            self.sortByDimension(nodes, i)\n",
    "            nodeList.extend(nodes, i)\n",
    "        self.list = nodeList\n",
    "\n",
    "\n",
    "    def sortByDimension(self, nodes, i):\n",
    "        \"\"\"Sorts the list of nodes by the i-th value of the contained points.\"\"\"\n",
    "        # build a list of tuples of (point[i], node)\n",
    "        decorated = [(node.cargo[i], node) for node in nodes]\n",
    "        # sort by this value\n",
    "        decorated.sort()\n",
    "        # write back to original list\n",
    "        nodes[:] = [node for (_, node) in decorated]\n",
    "            \n",
    "            \n",
    "            \n",
    "class MultiList: \n",
    "    \"\"\"A special data structure needed by FonsecaHyperVolume. \n",
    "    \n",
    "    It consists of several doubly linked lists that share common nodes. So, \n",
    "    every node has multiple predecessors and successors, one in every list.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    class Node: \n",
    "        \n",
    "        def __init__(self, numberLists, cargo=None): \n",
    "            self.cargo = cargo \n",
    "            self.next  = [None] * numberLists\n",
    "            self.prev = [None] * numberLists\n",
    "            self.ignore = 0\n",
    "            self.area = [0.0] * numberLists\n",
    "            self.volume = [0.0] * numberLists\n",
    "    \n",
    "        def __str__(self): \n",
    "            return str(self.cargo)\n",
    "        \n",
    "        \n",
    "    def __init__(self, numberLists):  \n",
    "        \"\"\"Constructor. \n",
    "        \n",
    "        Builds 'numberLists' doubly linked lists.\n",
    "\n",
    "        \"\"\"\n",
    "        self.numberLists = numberLists\n",
    "        self.sentinel = MultiList.Node(numberLists)\n",
    "        self.sentinel.next = [self.sentinel] * numberLists\n",
    "        self.sentinel.prev = [self.sentinel] * numberLists  \n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        strings = []\n",
    "        for i in xrange(self.numberLists):\n",
    "            currentList = []\n",
    "            node = self.sentinel.next[i]\n",
    "            while node != self.sentinel:\n",
    "                currentList.append(str(node))\n",
    "                node = node.next[i]\n",
    "            strings.append(str(currentList))\n",
    "        stringRepr = \"\"\n",
    "        for string in strings:\n",
    "            stringRepr += string + \"\\n\"\n",
    "        return stringRepr\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of lists that are included in this MultiList.\"\"\"\n",
    "        return self.numberLists\n",
    "    \n",
    "    \n",
    "    def getLength(self, i):\n",
    "        \"\"\"Returns the length of the i-th list.\"\"\"\n",
    "        length = 0\n",
    "        sentinel = self.sentinel\n",
    "        node = sentinel.next[i]\n",
    "        while node != sentinel:\n",
    "            length += 1\n",
    "            node = node.next[i]\n",
    "        return length\n",
    "            \n",
    "            \n",
    "    def append(self, node, index):\n",
    "        \"\"\"Appends a node to the end of the list at the given index.\"\"\"\n",
    "        lastButOne = self.sentinel.prev[index]\n",
    "        node.next[index] = self.sentinel\n",
    "        node.prev[index] = lastButOne\n",
    "        # set the last element as the new one\n",
    "        self.sentinel.prev[index] = node\n",
    "        lastButOne.next[index] = node\n",
    "        \n",
    "        \n",
    "    def extend(self, nodes, index):\n",
    "        \"\"\"Extends the list at the given index with the nodes.\"\"\"\n",
    "        sentinel = self.sentinel\n",
    "        for node in nodes:\n",
    "            lastButOne = sentinel.prev[index]\n",
    "            node.next[index] = sentinel\n",
    "            node.prev[index] = lastButOne\n",
    "            # set the last element as the new one\n",
    "            sentinel.prev[index] = node\n",
    "            lastButOne.next[index] = node\n",
    "        \n",
    "        \n",
    "    def remove(self, node, index, bounds): \n",
    "        \"\"\"Removes and returns 'node' from all lists in [0, 'index'[.\"\"\"\n",
    "        for i in xrange(index): \n",
    "            predecessor = node.prev[i]\n",
    "            successor = node.next[i]\n",
    "            predecessor.next[i] = successor\n",
    "            successor.prev[i] = predecessor  \n",
    "            if bounds[i] > node.cargo[i]:\n",
    "                bounds[i] = node.cargo[i]\n",
    "        return node\n",
    "    \n",
    "    \n",
    "    def reinsert(self, node, index, bounds):\n",
    "        \"\"\"\n",
    "        Inserts 'node' at the position it had in all lists in [0, 'index'[\n",
    "        before it was removed. This method assumes that the next and previous \n",
    "        nodes of the node that is reinserted are in the list.\n",
    "\n",
    "        \"\"\"\n",
    "        for i in xrange(index): \n",
    "            node.prev[i].next[i] = node\n",
    "            node.next[i].prev[i] = node\n",
    "            if bounds[i] > node.cargo[i]:\n",
    "                bounds[i] = node.cargo[i]         \n",
    "     \n",
    "    \n",
    "\n",
    "print(\"Load HyperVolume module.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute fitness and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"savefig\", dpi=300)\n",
    "# plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "\n",
    "\n",
    "## params \n",
    "iterations_default = 10\n",
    "iterations_mlr = iterations_default * 10\n",
    "sample_size = 5000\n",
    "total_number_of_docs = 100\n",
    "debug = True\n",
    "\n",
    "## maintain iterations to consider\n",
    "iterations = iterations_default\n",
    "def set_iterations(opt_method):\n",
    "    global iterations\n",
    "    if opt_method == \"MLR\":\n",
    "        iterations = iterations_mlr\n",
    "    else:\n",
    "        iterations = iterations_default \n",
    "        \n",
    "        \n",
    "'''\n",
    "Prints an individuals\n",
    "'''\n",
    "def print_individual(ind):\n",
    "    print(\"Iteration: \" + str(ind[\"iteration\"]) \n",
    "                  + \" | Individual: \" + str(ind[\"individual\"]) \n",
    "                  + \" | Avg overhead: \" + str(ind[\"avg_overhead\"]) \n",
    "                  + \" | Avg performance: \" + str(ind[\"avg_routing\"]))\n",
    "    print(\"\\tConfiguration:\")\n",
    "    for knob, knob_value in ind[\"knobs\"].iteritems():\n",
    "        print(\"\\t\\t\" + str(knob) + \": \" + str(knob_value))\n",
    "         \n",
    "\n",
    "'''\n",
    "Calculate the rolling/moving average\n",
    "'''\n",
    "def calculate_moving_average(aList):\n",
    "    moving_avg = 0\n",
    "    tmp_count = 0\n",
    "    for r in range(len(aList)):\n",
    "        moving_avg = (moving_avg * tmp_count + aList[r]) / (tmp_count + 1)\n",
    "        tmp_count = tmp_count + 1\n",
    "    return moving_avg\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the fitness of all individuals of the given runs and \n",
    "stores the fitness of an individual to the individual.\n",
    "Returns a dictionary where the key is the id of the run and the\n",
    "value are all individuals of this run.\n",
    "'''\n",
    "def compute_fitness(rtx_runs, data):\n",
    "    global worst_avg_overhead\n",
    "    global worst_avg_routing\n",
    "    global best_avg_overhead\n",
    "    global best_avg_routing\n",
    "        \n",
    "    run_to_all_individuals = dict()\n",
    "    # counter how often evaluations have been reused over all rtx runs\n",
    "    number_of_reuse_per_run = []\n",
    "    \n",
    "    # for each run\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all documents = all evaluations\n",
    "        all_documents = [d[\"_source\"] for d in data if d[\"parent\"] == rtx_run_id]\n",
    "        try:\n",
    "            opt_method = rtx_run[\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"MLR\"\n",
    "        # set iterations\n",
    "        set_iterations(opt_method)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"================================================================\")\n",
    "        print(\"Run: \" + rtx_run_id + \" | \" + opt_method \n",
    "              + \" | seed: \" + str(rtx_run[\"seed\"]) \n",
    "              + \" | number of docs/evals: \" + str(len(all_documents))\n",
    "              + \" | iterations to process: \" + str(iterations))\n",
    "        if debug:\n",
    "            print(\"================================================================\")\n",
    "\n",
    "        # counter how often evaluations have been reused for this rtx run\n",
    "        number_of_reuse = 0\n",
    "        # all inidividuals across all iterations\n",
    "        all_individuals = []\n",
    "        # for each iteration\n",
    "        for i in range(0, iterations):\n",
    "            # get documents of the given iteration for the given run\n",
    "            documents_of_iteration = [d for d in all_documents if d[\"iteration\"] == i]\n",
    "            pop_size = len(documents_of_iteration)\n",
    "            if debug:\n",
    "                print(\"Iteration: \" + str(i) + \" | Population size: \" + str(pop_size))\n",
    "\n",
    "            # for each individual of the iteration\n",
    "            for j in range(len(documents_of_iteration)):\n",
    "                new_inds = [d for d in documents_of_iteration if d[\"individual\"] == j]\n",
    "                if len(new_inds) > 1:\n",
    "                    print(\"ERROR: More than one individual with the same number within the same iteration\")\n",
    "                individual = new_inds[0]\n",
    "                # get overheads of individual\n",
    "                overheads = individual[\"payload\"][\"overheads\"]\n",
    "                # get routings of individual\n",
    "                routings = individual[\"payload\"][\"routings\"]\n",
    "                if overheads == [-1]:\n",
    "                    # print(\"Reuse\")\n",
    "                    avg_overhead = individual[\"payload\"][\"avg_overhead\"] \n",
    "                    moving_avg_routing = individual[\"payload\"][\"avg_routing\"] # was a BUG: used avg_routing =\n",
    "                    number_of_reuse = number_of_reuse + 1\n",
    "                else:\n",
    "                    if len(overheads) <> sample_size:\n",
    "                        print(\"ERROR: Overhead entries \" + str(len(overheads)) \n",
    "                              + \"<> sample size \" + str(sample_size))\n",
    "                    avg_overhead = np.mean(overheads) \n",
    "                    # avg_routing = np.mean(routings)\n",
    "                    # calculate moving average of routings\n",
    "                    moving_avg_routing = calculate_moving_average(routings) \n",
    "\n",
    "                # store fitness values in the individual\n",
    "                individual[\"avg_overhead\"] = avg_overhead\n",
    "                individual[\"avg_routing\"] = moving_avg_routing\n",
    "\n",
    "                # check for worst case\n",
    "                if avg_overhead > worst_avg_overhead:\n",
    "                    worst_avg_overhead = avg_overhead\n",
    "                if avg_overhead < best_avg_overhead:\n",
    "                    best_avg_overhead = avg_overhead\n",
    "                if moving_avg_routing > worst_avg_routing:\n",
    "                    worst_avg_routing = moving_avg_routing\n",
    "                if moving_avg_routing < best_avg_routing:\n",
    "                    best_avg_routing = moving_avg_routing\n",
    "\n",
    "                if debug:\n",
    "                    print(\"Individual: \" + str(individual[\"individual\"]) \n",
    "                         + \" | Overhead: \" + str(individual[\"avg_overhead\"])\n",
    "                         + \" | Routing: \" + str(individual[\"avg_routing\"]))\n",
    "\n",
    "                all_individuals.append(individual)\n",
    "                # next individual\n",
    "\n",
    "            # next iteration\n",
    "            if debug:\n",
    "                print(\"\")\n",
    "\n",
    "        if len(all_documents) == total_number_of_docs:\n",
    "            run_to_all_individuals[rtx_run_id] = all_individuals\n",
    "        else:\n",
    "            print(\"Skip run for further analysis, only \" + str(len(all_documents)) + \" documents/evaluations present.\")\n",
    "        # print(\"Number of reused evaluations: \" + str(number_of_reuse))\n",
    "        number_of_reuse_per_run.append(number_of_reuse)\n",
    "        # next run\n",
    "    print(\"Min | Average | Max number of reused evaluations per run: \"\n",
    "          + str(np.min(number_of_reuse_per_run)) + \" | \"\n",
    "          + str(np.mean(number_of_reuse_per_run)) + \" | \"\n",
    "          + str(np.max(number_of_reuse_per_run)) + \" | \"\n",
    "          + \"\\n==========================================================\")\n",
    "    return run_to_all_individuals\n",
    "      \n",
    "\n",
    "# worst and best objective values achieved in *all* runs\n",
    "worst_avg_overhead = sys.float_info.min\n",
    "worst_avg_routing = sys.float_info.min\n",
    "best_avg_overhead = sys.float_info.max\n",
    "best_avg_routing = sys.float_info.max\n",
    "\n",
    "# compute fitness\n",
    "\n",
    "# random search \n",
    "random_run_inds_500 = compute_fitness(random_rtx_runs_500, random_data_500)\n",
    "random_run_inds_700 = compute_fitness(random_rtx_runs_700, random_data_700)\n",
    "random_run_inds_800 = compute_fitness(random_rtx_runs_800, random_data_800)\n",
    "\n",
    "# mlr \n",
    "mlr_run_inds_500 = compute_fitness(mlr_rtx_runs_500, mlr_data_500)\n",
    "mlr_run_inds_700 = compute_fitness(mlr_rtx_runs_700, mlr_data_700)\n",
    "mlr_run_inds_800 = compute_fitness(mlr_rtx_runs_800, mlr_data_800)\n",
    "    \n",
    "# novelty\n",
    "novelty_run_inds_500 = compute_fitness(novelty_rtx_runs_500, novelty_data_500)\n",
    "novelty_run_inds_700 = compute_fitness(novelty_rtx_runs_700, novelty_data_700)\n",
    "novelty_run_inds_800 = compute_fitness(novelty_rtx_runs_800, novelty_data_800)\n",
    "\n",
    "# nsga2\n",
    "nsga2_run_inds_500 = compute_fitness(nsga2_rtx_runs_500, nsga2_data_500)\n",
    "nsga2_run_inds_700 = compute_fitness(nsga2_rtx_runs_700, nsga2_data_700)\n",
    "nsga2_run_inds_800 = compute_fitness(nsga2_rtx_runs_800, nsga2_data_800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"savefig\", dpi=300)\n",
    "# plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "\n",
    "\n",
    "'''\n",
    "Method to take a list of individuals and return just the individuals which lie \n",
    "on the Pareto frontier, sorted into order.\n",
    "Default behaviour is to find the maximum for both X and Y objectives, but the option is\n",
    "available to specify maxX = False or maxY = False to find the minimum for either\n",
    "or both of the objectves.\n",
    "Adapted from: http://oco-carbon.com/metrics/find-pareto-frontiers-in-python/\n",
    "'''\n",
    "def get_pareto_front(Inds, maxX = False, maxY = False):\n",
    "    # Sort the list in either ascending or descending order of X\n",
    "    Inds.sort(key=lambda x: x[\"avg_overhead\"], reverse=maxX)\n",
    "    # Start the Pareto frontier with the first value in the sorted list\n",
    "    p_front = [Inds[0]]    \n",
    "    # Loop through the sorted list\n",
    "    for ind in Inds[1:]:\n",
    "        if maxY: \n",
    "            # Thomas: changed >= to >\n",
    "            if ind[\"avg_routing\"] > p_front[-1][\"avg_routing\"]: # Look for higher values of Y… \n",
    "                p_front.append(ind) # … and add them to the Pareto frontier\n",
    "        else:\n",
    "            # Thomas: changed <= to <\n",
    "            if ind[\"avg_routing\"] < p_front[-1][\"avg_routing\"]: # Look for lower values of Y…    \n",
    "                p_front.append(ind) # … and add them to the Pareto frontier\n",
    "    return p_front\n",
    "\n",
    "\n",
    "def analyze_and_plot(rtx_runs, run_to_all_individuals, plot_data = False):    \n",
    "    printmd(\"===========================================================\", \"red\")\n",
    "    # pareto fronts of all runs\n",
    "    pareto_fronts_of_all_runs = []\n",
    "    \n",
    "    opt_method = \"\"\n",
    "    if len(rtx_runs) > 0:\n",
    "        try:\n",
    "            opt_method = rtx_runs[0][\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"MLR\"\n",
    "\n",
    "    # set iterations\n",
    "    set_iterations(opt_method)\n",
    "    \n",
    "    # for each run\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all individuals of the run\n",
    "        all_individuals = run_to_all_individuals.get(rtx_run_id, None)\n",
    "        if all_individuals is None:\n",
    "            print(\"Encountered skipped run \" + str(rtx_run_id))\n",
    "        else:\n",
    "        \n",
    "            print(\"\\nRun: \" + rtx_run_id + \" | method: \" + opt_method \n",
    "                  + \" | seed: \" + str(rtx_run[\"seed\"]) \n",
    "                  + \" | number of documents/evaluations: \" + str(len(all_individuals)))\n",
    "\n",
    "            # compute pareto front of the run ####################################################\n",
    "            pareto_front_of_run = get_pareto_front(all_individuals)\n",
    "            pareto_fronts_of_all_runs.append(pareto_front_of_run)\n",
    "            if plot_data:\n",
    "                print(\"\\nPareto front of the run:\")\n",
    "                for p in pareto_front_of_run:\n",
    "                    print_individual(p)\n",
    "\n",
    "            # compute hypervolume ####################################################\n",
    "            reference_point = [worst_avg_overhead, worst_avg_routing]\n",
    "            print(\"Reference Point: \" + str(reference_point))\n",
    "            hyperVolume = HyperVolume(reference_point)\n",
    "\n",
    "            pareto_front_values = [[el[\"avg_overhead\"], el[\"avg_routing\"]] for el in pareto_front_of_run]\n",
    "            hv = hyperVolume.compute(pareto_front_values)\n",
    "            print(\"Hypervolume: \" + str(hv))\n",
    "\n",
    "            # plotting #################################################################\n",
    "            if plot_data:\n",
    "\n",
    "                if opt_method == \"NSGAII\" or opt_method == \"NoveltySearch\" or opt_method == \"MLR\":\n",
    "\n",
    "                    # plot all averages for all iterations ####################################################\n",
    "                    # Average Overhead\n",
    "                    fig, axes = plt.subplots()\n",
    "                    fig.suptitle('Evolution of average overheads', fontsize=16)    \n",
    "                    plt.xlabel('Iteration') \n",
    "                    plt.ylabel('Average Overhead')\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    min_avgo_over_iterations = []\n",
    "                    best_min = sys.float_info.max\n",
    "                    for i in range(iterations):\n",
    "                        new_y = [el[\"avg_overhead\"] for el in all_individuals if el[\"iteration\"] == i]\n",
    "                        if not isinstance(new_y, (list,)):\n",
    "                            new_y = [new_y]\n",
    "                        y.extend(new_y)\n",
    "                        x.extend([i]*len(new_y))\n",
    "                        min_new_y = min(new_y)\n",
    "                        if min_new_y < best_min:\n",
    "                            best_min = min_new_y\n",
    "                        min_avgo_over_iterations.append(best_min)\n",
    "\n",
    "                    plt.scatter(x,y, marker=\"+\", color='black', label='individual')\n",
    "                    plt.scatter(range(iterations), min_avgo_over_iterations, s=100, facecolors='none', \n",
    "                                edgecolors='r', label='perato front for average overhead')\n",
    "                    pylab.legend(loc='best')\n",
    "\n",
    "                    # Average Routing Performance ####################################################\n",
    "                    fig, axes = plt.subplots()\n",
    "                    fig.suptitle('Evolution of average routing performance', fontsize=16)    \n",
    "                    plt.xlabel('Iteration') \n",
    "                    plt.ylabel('Average Routing Performance')\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    min_avgp_over_iterations = []\n",
    "                    best_min = sys.float_info.max\n",
    "                    for i in range(iterations):\n",
    "                        new_y = [el[\"avg_routing\"] for el in all_individuals if el[\"iteration\"] == i]\n",
    "                        if not isinstance(new_y, (list,)):\n",
    "                            new_y = [new_y]\n",
    "                        y.extend(new_y)\n",
    "                        x.extend([i]*len(new_y))\n",
    "                        min_new_y = min(new_y)\n",
    "                        if min_new_y < best_min:\n",
    "                            best_min = min_new_y\n",
    "                        min_avgp_over_iterations.append(best_min)\n",
    "\n",
    "                    plt.scatter(x,y, marker=\"+\", color='black', label='individual')\n",
    "                    plt.scatter(range(iterations), min_avgp_over_iterations, s=100, \n",
    "                                facecolors='none', edgecolors='r', label='perato front for average overhead')\n",
    "                    pylab.legend(loc='best')\n",
    "\n",
    "\n",
    "                # print all individuals and pareto front ##############################\n",
    "                fig, axes = plt.subplots()\n",
    "                # axes.grid(True)\n",
    "                fig.suptitle('All individuals and the pareto front', fontsize=16)\n",
    "                avg_o = [el[\"avg_overhead\"] for el in all_individuals]\n",
    "                avg_p = [el[\"avg_routing\"] for el in all_individuals] \n",
    "\n",
    "                plt.ylabel('Average Routing Performance')\n",
    "                plt.xlabel('Average Overhead')\n",
    "                plt.scatter(avg_o,avg_p, marker=\"+\", color='black', label='Individual')\n",
    "                p_front_avg_o = [el[\"avg_overhead\"] for el in pareto_front_of_run]\n",
    "                p_front_avg_p = [el[\"avg_routing\"] for el in pareto_front_of_run] \n",
    "                if len(pareto_front_of_run) > 1:\n",
    "                    plt.plot(p_front_avg_o, p_front_avg_p, label=\"Pareto Front\")\n",
    "                else:\n",
    "                    plt.scatter(p_front_avg_o, p_front_avg_p, label=\"Pareto Front\")\n",
    "                pylab.legend(loc='best')\n",
    "                #for i,j in zip(avg_o,avg_p):\n",
    "                #    axes.annotate(str(i)+\", \"+str(j),xy=(i,j))\n",
    "\n",
    "\n",
    "                # print hypervolume ####################################################\n",
    "                if opt_method == \"NSGAII\" or opt_method == \"NoveltySearch\" or opt_method == \"MLR\":\n",
    "\n",
    "                    fig, axes = plt.subplots()\n",
    "                    fig.suptitle('Evolution of the Hypervolume', fontsize=16)    \n",
    "                    plt.ylabel('Hypervolume')\n",
    "                    plt.xlabel('Iteration') \n",
    "                    x = range(iterations)\n",
    "                    y = []\n",
    "                    current_pareto_front = []\n",
    "                    for i in range(iterations):\n",
    "                        new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "                        if not isinstance(new_inds, (list,)):\n",
    "                            new_inds = [new_inds]\n",
    "                        new_inds.extend(current_pareto_front)\n",
    "                        current_pareto_front = get_pareto_front(new_inds)\n",
    "                        current_pareto_front_values = [[el[\"avg_overhead\"], el[\"avg_routing\"]] \n",
    "                                                       for el in current_pareto_front]\n",
    "                        hv = hyperVolume.compute(current_pareto_front_values)\n",
    "                        y.append(hv)\n",
    "\n",
    "                    plt.plot(x,y, color='black', label='Hypervolume')\n",
    "                    pylab.legend(loc='best')\n",
    "\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "    return pareto_fronts_of_all_runs\n",
    "\n",
    "\n",
    "# analyze and plot data\n",
    "\n",
    "# random search\n",
    "random_500_pfronts = analyze_and_plot(random_rtx_runs_500, random_run_inds_500)\n",
    "random_700_pfronts = analyze_and_plot(random_rtx_runs_700, random_run_inds_700)\n",
    "random_800_pfronts = analyze_and_plot(random_rtx_runs_800, random_run_inds_800)\n",
    "\n",
    "# mlr\n",
    "mlr_500_pfronts = analyze_and_plot(mlr_rtx_runs_500, mlr_run_inds_500)\n",
    "mlr_700_pfronts = analyze_and_plot(mlr_rtx_runs_700, mlr_run_inds_700)\n",
    "mlr_800_pfronts = analyze_and_plot(mlr_rtx_runs_800, mlr_run_inds_800)\n",
    "    \n",
    "# novelty\n",
    "novelty_500_pfronts = analyze_and_plot(novelty_rtx_runs_500, novelty_run_inds_500)\n",
    "novelty_700_pfronts = analyze_and_plot(novelty_rtx_runs_700, novelty_run_inds_700)\n",
    "novelty_800_pfronts = analyze_and_plot(novelty_rtx_runs_800, novelty_run_inds_800)\n",
    "\n",
    "# nsga2\n",
    "nsga2_500_pfronts = analyze_and_plot(nsga2_rtx_runs_500, nsga2_run_inds_500)\n",
    "nsga2_700_pfronts = analyze_and_plot(nsga2_rtx_runs_700, nsga2_run_inds_700)\n",
    "nsga2_800_pfronts = analyze_and_plot(nsga2_rtx_runs_800, nsga2_run_inds_800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the hypervolume and objectives over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "reference_point = [worst_avg_overhead, worst_avg_routing]\n",
    "hyperVolume = HyperVolume(reference_point)\n",
    "\n",
    "'''\n",
    "Computes the hypervolumes for all pareto fronts\n",
    "'''\n",
    "def compute_hvs(pfronts):\n",
    "    hvs = []\n",
    "    for pfront in pfronts:\n",
    "        pfront_values = [[el[\"avg_overhead\"], el[\"avg_routing\"]] for el in pfront]\n",
    "        hv = hyperVolume.compute(pfront_values)\n",
    "        hvs.append(hv)       \n",
    "    return hvs\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the average hypervolumes for all pareto fronts\n",
    "'''\n",
    "def compute_avg_hv(pfronts):\n",
    "    hvs = compute_hvs(pfronts)        \n",
    "    return np.mean(hvs)\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the median hypervolumes for all pareto fronts\n",
    "'''\n",
    "def compute_median_hv(pfronts, plotting=False):\n",
    "    hvs = compute_hvs(pfronts)\n",
    "        \n",
    "    if plotting:\n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(hvs, bins=30)  \n",
    "        plt.ylabel('frequency')\n",
    "        plt.xlabel('hypervolume')\n",
    "\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.boxplot(hvs, 0, '', positions=range(1))\n",
    "        ax.plot([\"1\"], np.mean(hvs), \".\", label='mean', color='black', linestyle=':')\n",
    "        plt.ylabel('hypervolume')\n",
    "        \n",
    "        plt.show() \n",
    "        \n",
    "    return np.median(hvs)\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the average of the avg overhead and avg routing over all runs' pareto fronts\n",
    "'''\n",
    "def compute_avg_objectives(pfronts):\n",
    "    avg_overheads_of_runs, avg_routings_of_runs = get_objectives_of_runs(pfronts)\n",
    "    return np.mean(avg_overheads_of_runs), np.mean(avg_routings_of_runs)\n",
    "\n",
    "'''\n",
    "Computes the median of the avg overhead and avg routing over all runs' pareto fronts\n",
    "'''\n",
    "def compute_median_objectives(pfronts):\n",
    "    avg_overheads_of_runs, avg_routings_of_runs = get_objectives_of_runs(pfronts)\n",
    "    return np.median(avg_overheads_of_runs), np.median(avg_routings_of_runs)\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the average of the avg overhead and avg routing for each run's pareto front\n",
    "'''\n",
    "def get_objectives_of_runs(pfronts, plotting=False):\n",
    "    avg_overheads_of_runs = []\n",
    "    avg_routings_of_runs = []\n",
    "    # for each run/seed\n",
    "    for pfront in pfronts:\n",
    "        avg_overheads = [el[\"avg_overhead\"] for el in pfront]\n",
    "        avg_overheads_of_runs.append(np.mean(avg_overheads))\n",
    "        avg_routings = [el[\"avg_routing\"] for el in pfront]\n",
    "        avg_routings_of_runs.append(np.mean(avg_routings))\n",
    "        \n",
    "    if plotting:\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.boxplot(avg_overheads_of_runs, 0, '', positions=range(1))\n",
    "        ax.plot([\"1\"], np.mean(avg_overheads_of_runs), \".\", label='mean', color='black', linestyle=':')\n",
    "        plt.ylabel('overheads of trips')\n",
    "\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.boxplot(avg_routings_of_runs, 0, '', positions=range(1))\n",
    "        ax.plot([\"1\"], np.mean(avg_routings_of_runs), \".\", label='mean', color='black', linestyle=':')\n",
    "        plt.ylabel('routings of trips')\n",
    "        \n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(avg_overheads_of_runs, bins=30)  \n",
    "        plt.ylabel('number of overheads')\n",
    "        plt.xlabel('trip overhead')\n",
    "        \n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(avg_routings_of_runs, bins=30)  \n",
    "        plt.ylabel('number of routing costs')\n",
    "        plt.xlabel('routing costs')\n",
    "           \n",
    "        plt.show() \n",
    "\n",
    "    return avg_overheads_of_runs, avg_routings_of_runs\n",
    "\n",
    "\n",
    "def compute_utility(pfronts, normalize=True, plotting=False):\n",
    "    all_utilities = []\n",
    "    for pfront in pfronts:\n",
    "        pfront_values = [[el[\"avg_overhead\"], el[\"avg_routing\"]] for el in pfront]\n",
    "        utilities_of_one_front = []\n",
    "        for solution in pfront_values:\n",
    "            avg_overhead = solution[0]\n",
    "            if normalize:\n",
    "                avg_overhead = normalize_avg_overhead(avg_overhead)\n",
    "            avg_routing = solution[1]\n",
    "            if normalize:\n",
    "                avg_routing = normalize_avg_routing(avg_routing)\n",
    "            utility = avg_overhead + avg_routing\n",
    "            utilities_of_one_front.append(utility)\n",
    "        all_utilities.append(np.mean(utilities_of_one_front))\n",
    "    \n",
    "    if plotting:\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.boxplot(all_utilities, 0, '', positions=range(1))\n",
    "        ax.plot([\"1\"], np.mean(all_utilities), \".\", label='mean', color='black', linestyle=':')\n",
    "        plt.ylabel('utility')\n",
    "        plt.show() \n",
    "\n",
    "    return all_utilities\n",
    "\n",
    "\n",
    "def compute_avg_utility(pfronts, normalize=True, plotting=False):\n",
    "    all_utilities = compute_utility(pfronts, normalize, plotting)\n",
    "    return np.mean(all_utilities)\n",
    "\n",
    "\n",
    "def compute_median_utility(pfronts, normalize=True, plotting=False):\n",
    "    all_utilities = compute_utility(pfronts, normalize, plotting)\n",
    "    return np.median(all_utilities)\n",
    "\n",
    "\n",
    "def normalize_avg_overhead(avg_overhead):\n",
    "    result = (float(avg_overhead-best_avg_overhead))/(float(worst_avg_overhead-best_avg_overhead))\n",
    "    # print(\"Overhead: \" + str(avg_overhead) + \" => \" + str(result))\n",
    "    if result < 0 or result > 1:\n",
    "        print(\"ERROR\")\n",
    "    return result\n",
    "\n",
    "def normalize_avg_routing(avg_routing):\n",
    "    result = (float(avg_routing-best_avg_routing))/(float(worst_avg_routing-best_avg_routing))\n",
    "    # print(\"Routing: \" + str(avg_routing) + \" => \" + str(result))\n",
    "    if result < 0 or result > 1:\n",
    "        print(\"ERROR\")\n",
    "    return result\n",
    "\n",
    "\n",
    "'''\n",
    "List of lists, one for each run containing how the hypervolume evolves with each fitness evaluation.\n",
    "'''\n",
    "def compute_hv_over_evals(rtx_runs, run_to_all_individuals, opt_method):\n",
    "    # set iterations\n",
    "    set_iterations(opt_method)\n",
    "    \n",
    "    hv_series_of_all_runs = []\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all individuals of the run\n",
    "        all_individuals = run_to_all_individuals.get(rtx_run_id, None)\n",
    "        if all_individuals is None:\n",
    "            print(\"No documents for run \" + str(rtx_run_id))\n",
    "            break\n",
    "       \n",
    "        # debug_msg = \"\"\n",
    "        hv_series = []          \n",
    "        current_pareto_front = []\n",
    "        for i in range(iterations):\n",
    "            new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "            if not isinstance(new_inds, (list,)):\n",
    "                new_inds = [new_inds]\n",
    "            for j in range(len(new_inds)):\n",
    "                # list with one element\n",
    "                new_ind = [el for el in new_inds if el[\"individual\"] == j]\n",
    "                if len(new_ind) > 1:\n",
    "                    print(\"ERROR: More than one individual with the same number within the same iteration.\")\n",
    "                # debug_msg = debug_msg + \"(\" + str(new_ind[0][\"iteration\"]) + \", \" + str(new_ind[0][\"individual\"]) + \")\"\n",
    "                current_pareto_front.append(new_ind[0])\n",
    "                current_pareto_front = get_pareto_front(current_pareto_front)\n",
    "                current_pareto_front_values = [[el[\"avg_overhead\"], el[\"avg_routing\"]] \n",
    "                                               for el in current_pareto_front]\n",
    "                hv = hyperVolume.compute(current_pareto_front_values)\n",
    "                hv_series.append(hv)\n",
    "        # print(debug_msg)    \n",
    "        hv_series_of_all_runs.append(hv_series)\n",
    "    return hv_series_of_all_runs\n",
    "    \n",
    "\n",
    "'''\n",
    "Plots the evolution of the hypervolume of the methods over fitness evaluations. \n",
    "The hypervolume is the \"Mean\" or the \"Median\" over the runs for each method.\n",
    "'''\n",
    "def plot_hypervolume_evolution(random_rtx_runs, random_run_to_all_individuals,\n",
    "                               nsga2_rtx_runs, nsga2_run_to_all_individuals,\n",
    "                               novelty_rtx_runs, novelty_run_to_all_individuals,\n",
    "                               mlr_rtx_runs, mlr_run_to_all_individuals, cars_number, mean_or_median = \"Mean\"):\n",
    "    methods = [\"Random\", \"NSGA2\", \"Novelty\", \"MLR\"]\n",
    "    linestyles = ['--', '-', '-.', ':']\n",
    "    \n",
    "    random_hv_series = compute_hv_over_evals(random_rtx_runs, random_run_to_all_individuals, methods[0])\n",
    "    nsga2_hv_series = compute_hv_over_evals(nsga2_rtx_runs, nsga2_run_to_all_individuals, methods[1])\n",
    "    novelty_hv_series = compute_hv_over_evals(novelty_rtx_runs, novelty_run_to_all_individuals, methods[2])\n",
    "    mlr_hv_series = compute_hv_over_evals(mlr_rtx_runs, mlr_run_to_all_individuals, methods[3])\n",
    "    \n",
    "    all_hv_series = [random_hv_series, nsga2_hv_series, novelty_hv_series, mlr_hv_series]\n",
    "    \n",
    "    fig, axes = plt.subplots()\n",
    "    fig.suptitle(\"Evolution of the \" + mean_or_median \n",
    "                 + \" Hypervolume (\" + str(cars_number) + \"cars)\", fontsize=16)    \n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.xlabel('Fitness Evaluations')\n",
    "    \n",
    "    for i in range(len(methods)):\n",
    "        method = methods[i]\n",
    "        hv_series = all_hv_series[i]\n",
    "        a = np.array(hv_series)\n",
    "        \n",
    "        if mean_or_median == \"Mean\":\n",
    "            plot_data = np.mean(a, axis=0)\n",
    "            print(method + \" - final mean hv: \" + str(plot_data[99]))\n",
    "        elif mean_or_median == \"Median\":\n",
    "            plot_data = np.median(a, axis=0)\n",
    "        else:\n",
    "            print(\"ERROR: First parameter must be mean or median.\")\n",
    "            \n",
    "        plt.plot(range(len(plot_data)), plot_data, color='black', linestyle=linestyles[i], label=method)\n",
    "     \n",
    "    pylab.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_hypervolume_boxplots(random_pfronts, nsga2_pfronts, novelty_pfronts, mlr_pfronts, cars_number):\n",
    "    hvs_random = compute_hvs(random_pfronts)\n",
    "    hvs_nsga2 = compute_hvs(nsga2_pfronts)\n",
    "    hvs_novelty = compute_hvs(novelty_pfronts)\n",
    "    hvs_mlr = compute_hvs(mlr_pfronts)\n",
    "\n",
    "    hvs = [hvs_random, hvs_nsga2, hvs_novelty, hvs_mlr]\n",
    "    hvs_names = [\"Random\", \"NSGA2\", \"Novelty\", \"MLR\"]\n",
    "    hvs_labels = range(1,5)\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(hvs, 0, '', positions=hvs_labels)\n",
    "    for i in range(len(hvs)):\n",
    "        ax.plot(hvs_labels[i], np.mean(hvs[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(hvs_labels, hvs_names) \n",
    "    plt.ylabel('hypervolume')\n",
    "    plt.show() \n",
    "    \n",
    "    # statistical tests\n",
    "    run_ttest(hvs, hvs_names)\n",
    "\n",
    "    \n",
    "def plot_objectives_boxplots(random_pfronts, nsga2_pfronts, novelty_pfronts, mlr_pfronts, cars_number):\n",
    "    overheads_random, routings_random = get_objectives_of_runs(random_pfronts) \n",
    "    overheads_nsga2, routings_nsga2 = get_objectives_of_runs(nsga2_pfronts) \n",
    "    overheads_novelty, routings_novelty = get_objectives_of_runs(novelty_pfronts)  \n",
    "    overheads_mlr, routings_mlr = get_objectives_of_runs(mlr_pfronts)\n",
    "    \n",
    "    overheads = [overheads_random, overheads_nsga2, overheads_novelty, overheads_mlr]\n",
    "    routings  = [routings_random, routings_nsga2, routings_novelty, routings_mlr]\n",
    "    names = [\"Random\", \"NSGA2\", \"Novelty\", \"MLR\"]\n",
    "    labels = range(1,5)\n",
    "    \n",
    "    # Trip overhead\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(overheads, 0, '', positions=labels)\n",
    "    for i in range(len(overheads)):\n",
    "        ax.plot(labels[i], np.mean(overheads[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(labels, names) \n",
    "    plt.ylabel('Trip Overhead')\n",
    "    plt.show()\n",
    "    \n",
    "    # statistical test #############\n",
    "    print(\"Trip Overhead:\")\n",
    "    run_ttest(overheads, names)\n",
    "    \n",
    "    # Routing Costs\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(routings, 0, '', positions=labels)\n",
    "    for i in range(len(routings)):\n",
    "        ax.plot(labels[i], np.mean(routings[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(labels, names) \n",
    "    plt.ylabel('Routing Costs')\n",
    "    plt.show() \n",
    "    \n",
    "    # statistical test #############\n",
    "    print(\"Routing Costs:\")\n",
    "    run_ttest(routings, names)\n",
    "            \n",
    "\n",
    "def run_ttest(data, names):\n",
    "    alpha = 0.05\n",
    "    for i in range(len(data)):\n",
    "        data_first = data[i]\n",
    "        name_first = names[i]\n",
    "        for j in range(len(names)):\n",
    "            if j == i:\n",
    "                break\n",
    "            data_second = data[j]\n",
    "            name_second = names[j]\n",
    "            statistic, pvalue = stats.ttest_ind(data_first, data_second, equal_var = False)\n",
    "            different_averages = bool(pvalue <= alpha)\n",
    "            is_is_not = \"\\tis\\t\" if different_averages else \"\\tis not\\t\"\n",
    "            print(name_first + is_is_not \n",
    "                  + \" statistically significantly different than \"+ name_second)\n",
    "\n",
    "            \n",
    "def check_avg(pfronts, name):\n",
    "    print(name + \" (\"+str(len(pfronts))+\" runs):\\t\" + str(compute_avg_hv(pfronts)) + \"\\t|\" \n",
    "         + str(compute_median_hv(pfronts)) + \"\\t| \" + str(compute_avg_utility(pfronts)) + \"\\t| \" \n",
    "         + str(compute_median_utility(pfronts)) + \"\\t| \"\n",
    "         + str(compute_avg_objectives(pfronts)) + \"\\t| \" + str(compute_median_objectives(pfronts)))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Iterations considered: \" + str(iterations))\n",
    "print(\"Average Hypervolume (the higher, the better) | Median Hypervolume | \" \n",
    "      + \"Average utility (the lower, the better) | Median utility | Average objectives | Median objectives\")\n",
    "\n",
    "\n",
    "print(\"500 cars\")\n",
    "check_avg(random_500_pfronts, \"Random\")\n",
    "check_avg(mlr_500_pfronts, \"MLR\")\n",
    "check_avg(novelty_500_pfronts, \"Novel\")\n",
    "check_avg(nsga2_500_pfronts, \"NSGAII\")\n",
    "\n",
    "print(\"700 cars\")\n",
    "check_avg(random_700_pfronts, \"Random\")\n",
    "check_avg(mlr_700_pfronts, \"MLR\")\n",
    "check_avg(novelty_700_pfronts, \"Novel\")\n",
    "check_avg(nsga2_700_pfronts, \"NSGAII\")\n",
    "\n",
    "print(\"800 cars\")\n",
    "check_avg(random_800_pfronts, \"Random\")\n",
    "check_avg(mlr_800_pfronts, \"MLR\")\n",
    "check_avg(novelty_800_pfronts, \"Novel\")\n",
    "check_avg(nsga2_800_pfronts, \"NSGAII\")\n",
    "\n",
    "# Hypervolume Boxplots ==========\n",
    "plot_hypervolume_boxplots(random_500_pfronts, nsga2_500_pfronts, novelty_500_pfronts, mlr_500_pfronts, 500)\n",
    "plot_hypervolume_boxplots(random_700_pfronts, nsga2_700_pfronts, novelty_700_pfronts, mlr_700_pfronts, 700)\n",
    "plot_hypervolume_boxplots(random_800_pfronts, nsga2_800_pfronts, novelty_800_pfronts, mlr_800_pfronts, 800)\n",
    "\n",
    "# Objectives Boxplots ==========\n",
    "plot_objectives_boxplots(random_500_pfronts, nsga2_500_pfronts, novelty_500_pfronts, mlr_500_pfronts, 500)\n",
    "plot_objectives_boxplots(random_700_pfronts, nsga2_700_pfronts, novelty_700_pfronts, mlr_700_pfronts, 700)\n",
    "plot_objectives_boxplots(random_800_pfronts, nsga2_800_pfronts, novelty_800_pfronts, mlr_800_pfronts, 800)\n",
    "\n",
    "# Hypervolume Evolution ==========\n",
    "plot_hypervolume_evolution(random_rtx_runs_500, random_run_inds_500,\n",
    "                           nsga2_rtx_runs_500, nsga2_run_inds_500,\n",
    "                          novelty_rtx_runs_500, novelty_run_inds_500,\n",
    "                           mlr_rtx_runs_500, mlr_run_inds_500, 500)\n",
    "\n",
    "plot_hypervolume_evolution(random_rtx_runs_700, random_run_inds_700,\n",
    "                           nsga2_rtx_runs_700, nsga2_run_inds_700,\n",
    "                           novelty_rtx_runs_700, novelty_run_inds_700,\n",
    "                           mlr_rtx_runs_700, mlr_run_inds_700, 700)\n",
    "\n",
    "plot_hypervolume_evolution(random_rtx_runs_800, random_run_inds_800,\n",
    "                           nsga2_rtx_runs_800, nsga2_run_inds_800,\n",
    "                           novelty_rtx_runs_800, novelty_run_inds_800,\n",
    "                           mlr_rtx_runs_800, mlr_run_inds_800, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (DEPRECATED) Analysis over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pfronts_over_runs(pfronts, combined_pront, method_name):\n",
    "    fig, axes = plt.subplots()\n",
    "    plt.ylabel('Average Routing Performance')\n",
    "    plt.xlabel('Average Overhead')\n",
    "    # axes.grid(True)\n",
    "    fig.suptitle(\"Pareto fronts over runs for \" + method_name, fontsize=16)\n",
    "    for pfront in pfronts:\n",
    "        avg_o = [el[\"avg_overhead\"] for el in pfront]\n",
    "        avg_p = [el[\"avg_routing\"] for el in pfront] \n",
    "        plt.plot(avg_o,avg_p, marker=\"+\", color='black', label='')\n",
    "\n",
    "    p_front_avg_o = [el[\"avg_overhead\"] for el in combined_pront]\n",
    "    p_front_avg_p = [el[\"avg_routing\"] for el in combined_pront] \n",
    "    if len(combined_pront) > 1:\n",
    "        plt.plot(p_front_avg_o, p_front_avg_p, label=\"Pareto Front over all runs\", color='red')\n",
    "    else:\n",
    "        plt.scatter(p_front_avg_o, p_front_avg_p, label=\"Pareto Front over all runs\")\n",
    "    # pylab.legend(loc='best')\n",
    "    #for i,j in zip(avg_o,avg_p):\n",
    "    #    axes.annotate(str(i)+\", \"+str(j),xy=(i,j))\n",
    "    \n",
    "\n",
    "def plot_combined_pfronts_over_methods(combined_pfronts, method_names, line_styles, colors):\n",
    "    fig, axes = plt.subplots()\n",
    "    plt.ylabel('Average Routing Performance')\n",
    "    plt.xlabel('Average Overhead')\n",
    "    # axes.grid(True)\n",
    "    fig.suptitle(\"Combined pareto fronts for each method\", fontsize=16)\n",
    "    for i in range(len(combined_pfronts)):\n",
    "        avg_o = [el[\"avg_overhead\"] for el in combined_pfronts[i]]\n",
    "        avg_p = [el[\"avg_routing\"] for el in combined_pfronts[i]] \n",
    "        if len(combined_pfronts[i]) > 1:\n",
    "            plt.plot(avg_o, avg_p, linestyle=line_styles[i], color=colors[i], label=method_names[i])\n",
    "        else:\n",
    "            plt.scatter(avg_o, avg_p, linestyle=line_styles[i], color=colors[i], label=method_names[i])\n",
    "    pylab.legend(loc='best')\n",
    "\n",
    "# Analyze pareto fronts over runs    \n",
    "\n",
    "# Random Search\n",
    "random_500_pfronts_flat = [ind for p_front in random_500_pfronts for ind in p_front]\n",
    "random_500_combined_pfront = get_pareto_front(random_500_pfronts_flat)\n",
    "plot_pfronts_over_runs(random_500_pfronts, random_500_combined_pfront, \"RandomSearch\")\n",
    "\n",
    "# MLR\n",
    "mlr_500_pfronts_flat = [ind for p_front in mlr_500_pfronts for ind in p_front]\n",
    "mlr_500_combined_pfront = get_pareto_front(mlr_500_pfronts_flat)\n",
    "plot_pfronts_over_runs(mlr_500_pfronts, mlr_500_combined_pfront, \"MLR\")\n",
    "\n",
    "# Novelty\n",
    "novelty_500_pfronts_flat = [ind for p_front in novelty_500_pfronts for ind in p_front]\n",
    "novelty_500_combined_pfront = get_pareto_front(novelty_500_pfronts_flat)\n",
    "plot_pfronts_over_runs(novelty_500_pfronts, novelty_500_combined_pfront, \"Novelty\")\n",
    "\n",
    "# NSGA2\n",
    "nsga2_500_pfronts_flat = [ind for p_front in nsga2_500_pfronts for ind in p_front]\n",
    "nsga2_500_combined_pfront = get_pareto_front(nsga2_500_pfronts_flat)\n",
    "plot_pfronts_over_runs(nsga2_500_pfronts, nsga2_500_combined_pfront, \"NSGAII\")\n",
    "\n",
    "\n",
    "###\n",
    "combined_pfronts_500 = [random_500_combined_pfront, mlr_500_combined_pfront, novelty_500_combined_pfront, nsga2_500_combined_pfront]\n",
    "\n",
    "#combined_500_pfronts_flat = [ind for p_front in combined_pfronts_500 for ind in p_front]\n",
    "#reference_front_500 = get_pareto_front(combined_500_pfronts_flat)\n",
    "#combined_pfronts_500.append(reference_front_500)\n",
    "\n",
    "method_names = [\"RandomSearch\", \"MLR\", \"Novelty\", \"NSGAII\"]\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "colors = ['b', 'g', 'r', 'c']\n",
    "plot_combined_pfronts_over_methods(combined_pfronts_500, method_names, line_styles, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Method to take two equally-sized lists and return just the elements which lie \n",
    "on the Pareto frontier, sorted into order.\n",
    "Default behaviour is to find the maximum for both X and Y, but the option is\n",
    "available to specify maxX = False or maxY = False to find the minimum for either\n",
    "or both of the parameters.\n",
    "'''\n",
    "def pareto_frontier(Xs, Ys, maxX = False, maxY = False):\n",
    "# Sort the list in either ascending or descending order of X\n",
    "    myList = sorted([[Xs[i], Ys[i]] for i in range(len(Xs))], reverse=maxX)\n",
    "# Start the Pareto frontier with the first value in the sorted list\n",
    "    p_front = [myList[0]]    \n",
    "# Loop through the sorted list\n",
    "    for pair in myList[1:]:\n",
    "        if maxY: \n",
    "            if pair[1] >= p_front[-1][1]: # Look for higher values of Y… \n",
    "                p_front.append(pair) # … and add them to the Pareto frontier\n",
    "        else:\n",
    "            if pair[1] <= p_front[-1][1]: # Look for lower values of Y…    \n",
    "                p_front.append(pair) # … and add them to the Pareto frontier\n",
    "# Turn resulting pairs back into a list of Xs and Ys\n",
    "    p_frontX = [pair[0] for pair in p_front]\n",
    "    p_frontY = [pair[1] for pair in p_front]\n",
    "    return p_frontX, p_frontY\n",
    "\n",
    "\n",
    "\n",
    "l = [[\"ind1\", 3.00, 12], [\"ind2\", 2.23, 13], [\"ind3\", 4.5, 15]]\n",
    "print(l)\n",
    "Is = [el[0] for el in l]\n",
    "Xs = [el[1] for el in l]\n",
    "Ys = [el[2] for el in l]\n",
    "print(Xs)\n",
    "print(Ys)\n",
    "\n",
    "pfront = pareto_frontier(Xs, Ys)\n",
    "print(pfront)\n",
    "s = zip(pfront[0], pfront[1])\n",
    "for e in s:\n",
    "    print(str(e[0]) + \" \" + str(e[1]))\n",
    "    \n",
    "unsorted_list = [['a','b','c','5','d'],['e','f','g','3','h'],['i','j','k','4','m']]\n",
    "print(unsorted_list)\n",
    "unsorted_list.sort(key=lambda x: x[3], reverse=False)\n",
    "print(unsorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[40, 50, 55], [50, 60, 60]])\n",
    "m1 = np.mean(a, axis=1)     # to take the mean of each row\n",
    "print(m1)\n",
    "m2 = np.mean(a, axis=0)     # to take the mean of each col\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
