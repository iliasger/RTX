{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness: (Median of overheads, Median of routing costs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from index thomas-nsga2-vm-large\n",
      "data retrieved from file raw_data/thomas-nsga2-vm-large.pickle\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "%reload_ext autoreload\n",
    "from notebooks_commons import get_raw_data\n",
    "\n",
    "\n",
    "# The first time we want to download the data from an index (might take a while!), \n",
    "# we should put the parameter load_from_db to True. Then, we can set it to False to \n",
    "# read the saved data from the local pickle file.\n",
    "def read_data(index, load_from_db = False):\n",
    "    print \"\\nReading from index \" + index\n",
    "    pair = get_raw_data(index, load_from_db)\n",
    "    rtx_runs = pair[0]\n",
    "    data     = pair[1] \n",
    "    return rtx_runs, data\n",
    "\n",
    "\n",
    "# Here we specify the name of the index to read data from\n",
    "\n",
    "large_index = \"thomas-nsga2-vm-large\" \n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "load_from_db = False\n",
    "\n",
    "### Get Novelty data\n",
    "large_runs, large_data = read_data(large_index, load_from_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness Function Loaded\n"
     ]
    }
   ],
   "source": [
    "use_median = True\n",
    "\n",
    "'''\n",
    "Returns the fitness of an individual\n",
    "'''\n",
    "def get_fitness(ind):\n",
    "    if use_median:\n",
    "        return ind[\"payload\"][\"median_overhead\"], ind[\"payload\"][\"median_routing\"]\n",
    "    else: \n",
    "        return ind[\"avg_overhead\"], ind[\"avg_routing\"]\n",
    "            \n",
    "'''\n",
    "Returns the overhead of an individual\n",
    "'''\n",
    "def get_overhead(ind):\n",
    "    if use_median:\n",
    "        return ind[\"payload\"][\"median_overhead\"]\n",
    "    else:\n",
    "        return ind[\"avg_overhead\"]\n",
    "    \n",
    "\n",
    "'''\n",
    "Returns the routing of an individual\n",
    "'''\n",
    "def get_routing(ind):\n",
    "    if use_median:\n",
    "        return ind[\"payload\"][\"median_routing\"]\n",
    "    else:\n",
    "        return ind[\"avg_routing\"]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def set_fitness_med(ind, overhead, routing):\n",
    "    ind[\"payload\"][\"median_overhead\"] = overhead\n",
    "    ind[\"payload\"][\"median_routing\"] = routing      \n",
    "\n",
    "        \n",
    "def set_fitness_avg(ind, overhead, routing):\n",
    "    ind[\"avg_overhead\"] = overhead\n",
    "    ind[\"avg_routing\"] = routing        \n",
    "\n",
    "    \n",
    "print(\"Fitness Function Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what's in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 runs performed by NSGAII\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>721\t\t| seed 1 | id AWg3yk2D-DH7UHKUO40M</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>1003\t\t| seed 2 | id AWg3ymDV-DH7UHKUO40N</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pprint\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string, color=None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "    \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def check_data(rtx_runs, data):\n",
    "    # sort according to seed \n",
    "    rtx_runs.sort(key=lambda d : d[\"seed\"])\n",
    "    opt_method = \"N/A\"\n",
    "    if len(rtx_runs) > 0:\n",
    "        try:\n",
    "            opt_method = rtx_runs[0][\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"BOGP\"\n",
    "    print \"There were \" + str(len(rtx_runs)) + \" runs performed by \" + opt_method\n",
    "\n",
    "    for rtx_run in rtx_runs:\n",
    "        data_for_run = [d for d in data if d[\"parent\"] == rtx_run[\"id\"]]\n",
    "        data_for_run.sort(key=lambda d : (d[\"_source\"][\"iteration\"], d[\"_source\"][\"individual\"]))\n",
    "        printmd(str(len(data_for_run)) + \"\\t\\t| seed \" + str(rtx_run[\"seed\"]) \n",
    "                + \" | id \" + str(rtx_run[\"id\"]), \"red\")\n",
    "\n",
    "        #for d in data_for_run:\n",
    "        #    s = d[\"_source\"]\n",
    "        #    overheads = s[\"payload\"][\"overheads\"]\n",
    "        #    routings = s[\"payload\"][\"routings\"]\n",
    "        #    printmd(\"Iteration \" + str(s[\"iteration\"]) + \", individual \" \n",
    "        #            + str(s[\"individual\"]) + \" with configuration\", \"blue\")        \n",
    "        #    pp.pprint(s[\"knobs\"])\n",
    "        #    printmd(\"has \" + str(len(overheads)) + \" overheads and \" \n",
    "        #            + str(len(routings)) + \" routings\", \"green\")\n",
    "\n",
    "\n",
    "\n",
    "check_data(large_runs, large_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for computing the hypervolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypervolume module loaded.\n"
     ]
    }
   ],
   "source": [
    "#    https://ls11-www.cs.tu-dortmund.de/rudolph/hypervolume/start\n",
    "\n",
    "#    Copyright (C) 2010 Simon Wessing\n",
    "#    TU Dortmund University\n",
    "#\n",
    "#    This program is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU General Public License as published by\n",
    "#    the Free Software Foundation, either version 3 of the License, or\n",
    "#    (at your option) any later version.\n",
    "#\n",
    "#    This program is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#    GNU General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU General Public License\n",
    "#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "__author__ = \"Simon Wessing\"\n",
    "\n",
    "\n",
    "class HyperVolume:\n",
    "    \"\"\"\n",
    "    Hypervolume computation based on variant 3 of the algorithm in the paper:\n",
    "    C. M. Fonseca, L. Paquete, and M. Lopez-Ibanez. An improved dimension-sweep\n",
    "    algorithm for the hypervolume indicator. In IEEE Congress on Evolutionary\n",
    "    Computation, pages 1157-1163, Vancouver, Canada, July 2006.\n",
    "\n",
    "    Minimization is implicitly assumed here!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, referencePoint):\n",
    "        \"\"\"Constructor.\"\"\"\n",
    "        self.referencePoint = referencePoint\n",
    "        self.list = []\n",
    "\n",
    "\n",
    "    def compute(self, front):\n",
    "        \"\"\"Returns the hypervolume that is dominated by a non-dominated front.\n",
    "\n",
    "        Before the HV computation, front and reference point are translated, so\n",
    "        that the reference point is [0, ..., 0].\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def weaklyDominates(point, other):\n",
    "            for i in xrange(len(point)):\n",
    "                if point[i] > other[i]:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        relevantPoints = []\n",
    "        referencePoint = self.referencePoint\n",
    "        dimensions = len(referencePoint)\n",
    "        for point in front:\n",
    "            # only consider points that dominate the reference point\n",
    "            if weaklyDominates(point, referencePoint):\n",
    "                relevantPoints.append(point)\n",
    "        if any(referencePoint):\n",
    "            # shift points so that referencePoint == [0, ..., 0]\n",
    "            # this way the reference point doesn't have to be explicitly used\n",
    "            # in the HV computation\n",
    "            for j in xrange(len(relevantPoints)):\n",
    "                relevantPoints[j] = [relevantPoints[j][i] - referencePoint[i] for i in xrange(dimensions)]\n",
    "        self.preProcess(relevantPoints)\n",
    "        bounds = [-1.0e308] * dimensions\n",
    "        hyperVolume = self.hvRecursive(dimensions - 1, len(relevantPoints), bounds)\n",
    "        return hyperVolume\n",
    "\n",
    "\n",
    "    def hvRecursive(self, dimIndex, length, bounds):\n",
    "        \"\"\"Recursive call to hypervolume calculation.\n",
    "\n",
    "        In contrast to the paper, the code assumes that the reference point\n",
    "        is [0, ..., 0]. This allows the avoidance of a few operations.\n",
    "\n",
    "        \"\"\"\n",
    "        hvol = 0.0\n",
    "        sentinel = self.list.sentinel\n",
    "        if length == 0:\n",
    "            return hvol\n",
    "        elif dimIndex == 0:\n",
    "            # special case: only one dimension\n",
    "            # why using hypervolume at all?\n",
    "            return -sentinel.next[0].cargo[0]\n",
    "        elif dimIndex == 1:\n",
    "            # special case: two dimensions, end recursion\n",
    "            q = sentinel.next[1]\n",
    "            h = q.cargo[0]\n",
    "            p = q.next[1]\n",
    "            while p is not sentinel:\n",
    "                pCargo = p.cargo\n",
    "                hvol += h * (q.cargo[1] - pCargo[1])\n",
    "                if pCargo[0] < h:\n",
    "                    h = pCargo[0]\n",
    "                q = p\n",
    "                p = q.next[1]\n",
    "            hvol += h * q.cargo[1]\n",
    "            return hvol\n",
    "        else:\n",
    "            remove = self.list.remove\n",
    "            reinsert = self.list.reinsert\n",
    "            hvRecursive = self.hvRecursive\n",
    "            p = sentinel\n",
    "            q = p.prev[dimIndex]\n",
    "            while q.cargo != None:\n",
    "                if q.ignore < dimIndex:\n",
    "                    q.ignore = 0\n",
    "                q = q.prev[dimIndex]\n",
    "            q = p.prev[dimIndex]\n",
    "            while length > 1 and (q.cargo[dimIndex] > bounds[dimIndex] or q.prev[dimIndex].cargo[dimIndex] >= bounds[dimIndex]):\n",
    "                p = q\n",
    "                remove(p, dimIndex, bounds)\n",
    "                q = p.prev[dimIndex]\n",
    "                length -= 1\n",
    "            qArea = q.area\n",
    "            qCargo = q.cargo\n",
    "            qPrevDimIndex = q.prev[dimIndex]\n",
    "            if length > 1:\n",
    "                hvol = qPrevDimIndex.volume[dimIndex] + qPrevDimIndex.area[dimIndex] * (qCargo[dimIndex] - qPrevDimIndex.cargo[dimIndex])\n",
    "            else:\n",
    "                qArea[0] = 1\n",
    "                qArea[1:dimIndex+1] = [qArea[i] * -qCargo[i] for i in xrange(dimIndex)]\n",
    "            q.volume[dimIndex] = hvol\n",
    "            if q.ignore >= dimIndex:\n",
    "                qArea[dimIndex] = qPrevDimIndex.area[dimIndex]\n",
    "            else:\n",
    "                qArea[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
    "                if qArea[dimIndex] <= qPrevDimIndex.area[dimIndex]:\n",
    "                    q.ignore = dimIndex\n",
    "            while p is not sentinel:\n",
    "                pCargoDimIndex = p.cargo[dimIndex]\n",
    "                hvol += q.area[dimIndex] * (pCargoDimIndex - q.cargo[dimIndex])\n",
    "                bounds[dimIndex] = pCargoDimIndex\n",
    "                reinsert(p, dimIndex, bounds)\n",
    "                length += 1\n",
    "                q = p\n",
    "                p = p.next[dimIndex]\n",
    "                q.volume[dimIndex] = hvol\n",
    "                if q.ignore >= dimIndex:\n",
    "                    q.area[dimIndex] = q.prev[dimIndex].area[dimIndex]\n",
    "                else:\n",
    "                    q.area[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
    "                    if q.area[dimIndex] <= q.prev[dimIndex].area[dimIndex]:\n",
    "                        q.ignore = dimIndex\n",
    "            hvol -= q.area[dimIndex] * q.cargo[dimIndex]\n",
    "            return hvol\n",
    "\n",
    "\n",
    "    def preProcess(self, front):\n",
    "        \"\"\"Sets up the list data structure needed for calculation.\"\"\"\n",
    "        dimensions = len(self.referencePoint)\n",
    "        nodeList = MultiList(dimensions)\n",
    "        nodes = [MultiList.Node(dimensions, point) for point in front]\n",
    "        for i in xrange(dimensions):\n",
    "            self.sortByDimension(nodes, i)\n",
    "            nodeList.extend(nodes, i)\n",
    "        self.list = nodeList\n",
    "\n",
    "\n",
    "    def sortByDimension(self, nodes, i):\n",
    "        \"\"\"Sorts the list of nodes by the i-th value of the contained points.\"\"\"\n",
    "        # build a list of tuples of (point[i], node)\n",
    "        decorated = [(node.cargo[i], node) for node in nodes]\n",
    "        # sort by this value\n",
    "        decorated.sort()\n",
    "        # write back to original list\n",
    "        nodes[:] = [node for (_, node) in decorated]\n",
    "            \n",
    "            \n",
    "            \n",
    "class MultiList: \n",
    "    \"\"\"A special data structure needed by FonsecaHyperVolume. \n",
    "    \n",
    "    It consists of several doubly linked lists that share common nodes. So, \n",
    "    every node has multiple predecessors and successors, one in every list.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    class Node: \n",
    "        \n",
    "        def __init__(self, numberLists, cargo=None): \n",
    "            self.cargo = cargo \n",
    "            self.next  = [None] * numberLists\n",
    "            self.prev = [None] * numberLists\n",
    "            self.ignore = 0\n",
    "            self.area = [0.0] * numberLists\n",
    "            self.volume = [0.0] * numberLists\n",
    "    \n",
    "        def __str__(self): \n",
    "            return str(self.cargo)\n",
    "        \n",
    "        \n",
    "    def __init__(self, numberLists):  \n",
    "        \"\"\"Constructor. \n",
    "        \n",
    "        Builds 'numberLists' doubly linked lists.\n",
    "\n",
    "        \"\"\"\n",
    "        self.numberLists = numberLists\n",
    "        self.sentinel = MultiList.Node(numberLists)\n",
    "        self.sentinel.next = [self.sentinel] * numberLists\n",
    "        self.sentinel.prev = [self.sentinel] * numberLists  \n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        strings = []\n",
    "        for i in xrange(self.numberLists):\n",
    "            currentList = []\n",
    "            node = self.sentinel.next[i]\n",
    "            while node != self.sentinel:\n",
    "                currentList.append(str(node))\n",
    "                node = node.next[i]\n",
    "            strings.append(str(currentList))\n",
    "        stringRepr = \"\"\n",
    "        for string in strings:\n",
    "            stringRepr += string + \"\\n\"\n",
    "        return stringRepr\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of lists that are included in this MultiList.\"\"\"\n",
    "        return self.numberLists\n",
    "    \n",
    "    \n",
    "    def getLength(self, i):\n",
    "        \"\"\"Returns the length of the i-th list.\"\"\"\n",
    "        length = 0\n",
    "        sentinel = self.sentinel\n",
    "        node = sentinel.next[i]\n",
    "        while node != sentinel:\n",
    "            length += 1\n",
    "            node = node.next[i]\n",
    "        return length\n",
    "            \n",
    "            \n",
    "    def append(self, node, index):\n",
    "        \"\"\"Appends a node to the end of the list at the given index.\"\"\"\n",
    "        lastButOne = self.sentinel.prev[index]\n",
    "        node.next[index] = self.sentinel\n",
    "        node.prev[index] = lastButOne\n",
    "        # set the last element as the new one\n",
    "        self.sentinel.prev[index] = node\n",
    "        lastButOne.next[index] = node\n",
    "        \n",
    "        \n",
    "    def extend(self, nodes, index):\n",
    "        \"\"\"Extends the list at the given index with the nodes.\"\"\"\n",
    "        sentinel = self.sentinel\n",
    "        for node in nodes:\n",
    "            lastButOne = sentinel.prev[index]\n",
    "            node.next[index] = sentinel\n",
    "            node.prev[index] = lastButOne\n",
    "            # set the last element as the new one\n",
    "            sentinel.prev[index] = node\n",
    "            lastButOne.next[index] = node\n",
    "        \n",
    "        \n",
    "    def remove(self, node, index, bounds): \n",
    "        \"\"\"Removes and returns 'node' from all lists in [0, 'index'[.\"\"\"\n",
    "        for i in xrange(index): \n",
    "            predecessor = node.prev[i]\n",
    "            successor = node.next[i]\n",
    "            predecessor.next[i] = successor\n",
    "            successor.prev[i] = predecessor  \n",
    "            if bounds[i] > node.cargo[i]:\n",
    "                bounds[i] = node.cargo[i]\n",
    "        return node\n",
    "    \n",
    "    \n",
    "    def reinsert(self, node, index, bounds):\n",
    "        \"\"\"\n",
    "        Inserts 'node' at the position it had in all lists in [0, 'index'[\n",
    "        before it was removed. This method assumes that the next and previous \n",
    "        nodes of the node that is reinserted are in the list.\n",
    "\n",
    "        \"\"\"\n",
    "        for i in xrange(index): \n",
    "            node.prev[i].next[i] = node\n",
    "            node.next[i].prev[i] = node\n",
    "            if bounds[i] > node.cargo[i]:\n",
    "                bounds[i] = node.cargo[i]         \n",
    "     \n",
    "    \n",
    "\n",
    "print(\"Hypervolume module loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute fitness and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: AWg3yk2D-DH7UHKUO40M | NSGAII | seed: 1 | number of docs/evals: 721 | iterations to process: 100\n",
      "Run: AWg3ymDV-DH7UHKUO40N | NSGAII | seed: 2 | number of docs/evals: 1003 | iterations to process: 100\n",
      "Min | Average | Max number of reused evaluations per run: 220 | 367.0 | 514 | \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"savefig\", dpi=300)\n",
    "# plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "\n",
    "\n",
    "## params \n",
    "iterations_default = 100\n",
    "iterations_mlr = iterations_default * 10\n",
    "sample_size = 5000\n",
    "total_number_of_docs = 1000\n",
    "debug = False\n",
    "\n",
    "## maintain iterations to consider\n",
    "iterations = iterations_default\n",
    "def set_iterations(opt_method):\n",
    "    global iterations\n",
    "    if opt_method == \"BOGP\":\n",
    "        iterations = iterations_mlr\n",
    "    else:\n",
    "        iterations = iterations_default \n",
    "        \n",
    "        \n",
    "'''\n",
    "Prints an individuals\n",
    "'''\n",
    "def print_individual(ind):\n",
    "    print(\"Iteration: \" + str(ind[\"iteration\"]) \n",
    "                  + \" | Individual: \" + str(ind[\"individual\"]) \n",
    "                  + \" | Overhead: \" + str(get_overhead(ind)) \n",
    "                  + \" | Routing: \" + str(get_routing(ind)))\n",
    "    print(\"\\tConfiguration:\")\n",
    "    for knob, knob_value in ind[\"knobs\"].iteritems():\n",
    "        print(\"\\t\\t\" + str(knob) + \": \" + str(knob_value))\n",
    "\n",
    "    \n",
    "def get_config_key(ind):\n",
    "    knobs = ind[\"knobs\"]\n",
    "    key = str(knobs[\"re_route_every_ticks\"]) + \",\"\n",
    "    key = key + str(knobs[\"freshness_cut_off_value\"]) + \",\"\n",
    "    key = key + str(knobs[\"average_edge_duration_factor\"]) + \",\"\n",
    "    key = key + str(knobs[\"exploration_percentage\"]) + \",\"\n",
    "    key = key + str(knobs[\"freshness_update_factor\"]) + \",\"\n",
    "    key = key + str(knobs[\"route_random_sigma\"]) + \",\"\n",
    "    key = key + str(knobs[\"max_speed_and_length_factor\"])\n",
    "    return key\n",
    "  \n",
    "    \n",
    "'''\n",
    "Calculate the rolling/moving average\n",
    "'''\n",
    "def calculate_moving_average(aList):\n",
    "    moving_avg = 0\n",
    "    tmp_count = 0\n",
    "    for r in range(len(aList)):\n",
    "        moving_avg = (moving_avg * tmp_count + aList[r]) / (tmp_count + 1)\n",
    "        tmp_count = tmp_count + 1\n",
    "    return moving_avg\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the fitness of all individuals of the given runs and \n",
    "stores the fitness of an individual to the individual.\n",
    "Returns a dictionary where the key is the id of the run and the\n",
    "value are all individuals of this run.\n",
    "'''\n",
    "def compute_fitness(rtx_runs, data):\n",
    "    global worst_overhead\n",
    "    global worst_routing\n",
    "    global best_overhead\n",
    "    global best_routing\n",
    "        \n",
    "    run_to_all_individuals = dict()\n",
    "    # counter how often evaluations have been reused over all rtx runs\n",
    "    number_of_reuse_per_run = []\n",
    "    \n",
    "    # for each run\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all documents = all evaluations\n",
    "        all_documents = [d[\"_source\"] for d in data if d[\"parent\"] == rtx_run_id]\n",
    "        try:\n",
    "            opt_method = rtx_run[\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"BOGP\"\n",
    "        # set iterations\n",
    "        set_iterations(opt_method)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"================================================================\")\n",
    "        print(\"Run: \" + rtx_run_id + \" | \" + opt_method \n",
    "              + \" | seed: \" + str(rtx_run[\"seed\"]) \n",
    "              + \" | number of docs/evals: \" + str(len(all_documents))\n",
    "              + \" | iterations to process: \" + str(iterations))\n",
    "        if debug:\n",
    "            print(\"================================================================\")\n",
    "\n",
    "            \n",
    "        # counter how often evaluations have been reused for this rtx run\n",
    "        number_of_reuse = 0\n",
    "        # all inidividuals across all iterations\n",
    "        all_individuals = []\n",
    "        # stored fitnesses for reuse calculated with the fitness function using avg\n",
    "        fitness_store = dict()\n",
    "        \n",
    "        # for each iteration\n",
    "        for i in range(0, iterations):\n",
    "            # get documents of the given iteration for the given run\n",
    "            documents_of_iteration = [d for d in all_documents if d[\"iteration\"] == i]\n",
    "            pop_size = len(documents_of_iteration)\n",
    "            if debug:\n",
    "                print(\"Iteration: \" + str(i) + \" | Population size: \" + str(pop_size))\n",
    "\n",
    "            # for each individual of the iteration\n",
    "            for j in range(len(documents_of_iteration)):        \n",
    "                next_individuals = [d for d in documents_of_iteration if d[\"individual\"] == j]\n",
    "                if len(next_individuals) > 1:\n",
    "                    print(\"ERROR: more than one individual with same number within one iteration.\")\n",
    "                else:\n",
    "                    individual = next_individuals[0] # list of one elem\n",
    "\n",
    "                # get overheads of individual\n",
    "                overheads = individual[\"payload\"][\"overheads\"]\n",
    "                # get routings of individual\n",
    "                routings = individual[\"payload\"][\"routings\"]\n",
    "                if overheads == [-1]:\n",
    "                    # reused fitness evaluations are stored in these fields although \n",
    "                    # the fitness are not the average but the medians. \n",
    "                    med_overhead = individual[\"payload\"][\"avg_overhead\"]  \n",
    "                    med_routing = individual[\"payload\"][\"avg_routing\"]\n",
    "                    # store properly \"median\" fitness values in the individual\n",
    "                    set_fitness_med(individual, med_overhead, med_routing)\n",
    "                    # get fitness for average overhead and routing\n",
    "                    individual_key = get_config_key(individual)\n",
    "                    avg_overhead, avg_routing = fitness_store[individual_key]\n",
    "                    set_fitness_avg(individual, avg_overhead, avg_routing) \n",
    "                    if debug:\n",
    "                        print(\"Individual: \" + individual_key + \" | load fitness: \" \n",
    "                              + str(avg_overhead) + \" \" + str(avg_routing))\n",
    "                    # stats\n",
    "                    number_of_reuse = number_of_reuse + 1\n",
    "                else:\n",
    "                    # sanity checks -- fitness needs not to be computed and stored; it is already there\n",
    "                    if len(overheads) <> sample_size:\n",
    "                        print(\"ERROR: Overhead entries \" + str(len(overheads)) \n",
    "                              + \"<> sample size \" + str(sample_size))\n",
    "                    med_overhead = np.median(overheads) \n",
    "                    med_routing = np.median(routings)\n",
    "                    individual[\"payload\"][\"median_overhead\"] = med_overhead\n",
    "                    individual[\"payload\"][\"median_routing\"] = med_routing\n",
    "                    #med_overhead = individual[\"payload\"][\"median_overhead\"]\n",
    "                    #med_routing = individual[\"payload\"][\"median_routing\"]\n",
    "                    #if med_overhead <> computed_med_overhead:\n",
    "                    #    print(\"Overhead does not match: \" \n",
    "                    #          + str(med_overhead) + \" vs \" + str(computed_med_overhead))\n",
    "                    #if med_routing <> computed_med_routing:\n",
    "                    #    print(\"Routing does not match: \" \n",
    "                    #          + str(med_routing) + \" vs \" + str(computed_med_routing))\n",
    "                        \n",
    "                    # compute and store average values\n",
    "                    avg_overhead = np.mean(overheads)\n",
    "                    avg_routing = np.mean(routings) # calculate_moving_average(routings)\n",
    "                    set_fitness_avg(individual, avg_overhead, avg_routing)\n",
    "                    individual_key = get_config_key(individual)\n",
    "                    fitness_store[individual_key] = avg_overhead, avg_routing\n",
    "                    if debug:\n",
    "                        print(\"Individual: \" + individual_key + \" | store fitness: \" \n",
    "                              + str(avg_overhead) + \" \" + str(avg_routing))\n",
    "               \n",
    "                # use med or avg from now on\n",
    "                if use_median:   \n",
    "                    overhead = med_overhead\n",
    "                    routing = med_routing\n",
    "                else:\n",
    "                    overhead = avg_overhead\n",
    "                    routing = avg_routing\n",
    "                \n",
    "                # check for worst and best cases\n",
    "                if overhead > worst_overhead:\n",
    "                    worst_overhead = overhead\n",
    "                if overhead < best_overhead:\n",
    "                    best_overhead = overhead\n",
    "                if routing > worst_routing:\n",
    "                    worst_routing = routing\n",
    "                if routing < best_routing:\n",
    "                    best_routing = routing\n",
    "                    \n",
    "\n",
    "                if debug:\n",
    "                    print(\"Individual: \" + str(individual[\"individual\"]) \n",
    "                         + \" | Overhead: \" + str(get_overhead(individual))\n",
    "                         + \" | Routing: \" + str(get_routing(individual)))\n",
    "\n",
    "                all_individuals.append(individual)\n",
    "                # next individual\n",
    "\n",
    "            # next iteration\n",
    "            if debug:\n",
    "                print(\"\")\n",
    "\n",
    "        #if len(all_documents) == total_number_of_docs:\n",
    "        run_to_all_individuals[rtx_run_id] = all_individuals\n",
    "        #else:\n",
    "         #   print(\"Skip run for further analysis, only \" + str(len(all_documents)) \n",
    "          #        + \" documents/evaluations present.\")\n",
    "        number_of_reuse_per_run.append(number_of_reuse)\n",
    "        # next run\n",
    "    if len(number_of_reuse_per_run) > 0:\n",
    "        print(\"Min | Average | Max number of reused evaluations per run: \"\n",
    "              + str(np.min(number_of_reuse_per_run)) + \" | \"\n",
    "              + str(np.mean(number_of_reuse_per_run)) + \" | \"\n",
    "              + str(np.max(number_of_reuse_per_run)) + \" | \"\n",
    "              + \"\\n==========================================================\")\n",
    "    return run_to_all_individuals\n",
    "      \n",
    "\n",
    "# worst and best objective values achieved in *all* runs\n",
    "worst_overhead = sys.float_info.min\n",
    "worst_routing = sys.float_info.min\n",
    "best_overhead = sys.float_info.max\n",
    "best_routing = sys.float_info.max\n",
    "\n",
    "\n",
    "# check / store fitness\n",
    "large_run_inds = compute_fitness(large_runs, large_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>===========================================================</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run: AWg3yk2D-DH7UHKUO40M | method: NSGAII | seed: 1 | number of documents/evaluations: 721\n",
      "Reference Point: [1.8451166012704037, 154.0]\n",
      "Hypervolume: 32.5651395558\n",
      "\n",
      "Run: AWg3ymDV-DH7UHKUO40N | method: NSGAII | seed: 2 | number of documents/evaluations: 1003\n",
      "Reference Point: [1.8451166012704037, 154.0]\n",
      "Hypervolume: 33.4227298665\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"savefig\", dpi=300)\n",
    "# plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "\n",
    "\n",
    "'''\n",
    "Method to take a list of individuals and return just the individuals which lie \n",
    "on the Pareto frontier, sorted into order.\n",
    "Default behaviour is to find the maximum for both X and Y objectives, but the option is\n",
    "available to specify maxX = False or maxY = False to find the minimum for either\n",
    "or both of the objectves.\n",
    "Adapted from: http://oco-carbon.com/metrics/find-pareto-frontiers-in-python/\n",
    "'''\n",
    "def get_pareto_front(Inds, maxX = False, maxY = False):\n",
    "    # Sort the list in either ascending or descending order of X\n",
    "    Inds.sort(key=lambda x: get_overhead(x), reverse=maxX)\n",
    "    # Start the Pareto frontier with the first value in the sorted list\n",
    "    p_front = [Inds[0]]    \n",
    "    # Loop through the sorted list\n",
    "    for ind in Inds[1:]:\n",
    "        if maxY: \n",
    "            # changed >= to >\n",
    "            if get_routing(ind) > get_routing(p_front[-1]): # Look for higher values of Y… \n",
    "                p_front.append(ind) # … and add them to the Pareto frontier\n",
    "        else:\n",
    "            # changed <= to <\n",
    "            if get_routing(ind) < get_routing(p_front[-1]): # Look for lower values of Y…    \n",
    "                p_front.append(ind) # … and add them to the Pareto frontier\n",
    "    return p_front\n",
    "\n",
    "\n",
    "def analyze_and_plot(rtx_runs, run_to_all_individuals, plotting = False):    \n",
    "    printmd(\"===========================================================\", \"red\")\n",
    "    # pareto fronts of all runs\n",
    "    pareto_fronts_of_all_runs = []\n",
    "    \n",
    "    opt_method = \"\"\n",
    "    if len(rtx_runs) > 0:\n",
    "        try:\n",
    "            opt_method = rtx_runs[0][\"strategy\"][\"optimizer_method\"]\n",
    "        except:\n",
    "            # mlr does not store the opt method name in field strategy.optimizer_method\n",
    "            opt_method = \"BOGP\"\n",
    "\n",
    "    # set iterations\n",
    "    set_iterations(opt_method)\n",
    "    \n",
    "    # for each run\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all individuals of the run\n",
    "        all_individuals = run_to_all_individuals.get(rtx_run_id, None)\n",
    "        if all_individuals is None:\n",
    "            print(\"Encountered skipped run \" + str(rtx_run_id))\n",
    "        else:\n",
    "            print(\"\\nRun: \" + rtx_run_id + \" | method: \" + opt_method \n",
    "                  + \" | seed: \" + str(rtx_run[\"seed\"]) \n",
    "                  + \" | number of documents/evaluations: \" + str(len(all_individuals)))\n",
    "\n",
    "            # compute pareto front of the run ####################################################\n",
    "            pareto_front_of_run = get_pareto_front(all_individuals)\n",
    "            pareto_fronts_of_all_runs.append(pareto_front_of_run)\n",
    "            if plotting:\n",
    "                print(\"\\nPareto front of the run:\")\n",
    "                for p in pareto_front_of_run:\n",
    "                    print_individual(p)\n",
    "\n",
    "            # compute hypervolume ####################################################\n",
    "            reference_point = [worst_overhead, worst_routing]\n",
    "            print(\"Reference Point: \" + str(reference_point))\n",
    "            hyperVolume = HyperVolume(reference_point)\n",
    "\n",
    "            pareto_front_values = [[get_overhead(el), get_routing(el)] for el in pareto_front_of_run]\n",
    "            hv = hyperVolume.compute(pareto_front_values)\n",
    "            print(\"Hypervolume: \" + str(hv))\n",
    "\n",
    "            # plotting #################################################################\n",
    "            if plotting:\n",
    "\n",
    "                # Hypervolume over fitness evaluations ###########################\n",
    "                fig, axes = plt.subplots()\n",
    "                fig.suptitle('Evolution of the Hypervolume', fontsize=16)    \n",
    "                plt.xlabel('Fitness Evaluations') \n",
    "                x = range(total_number_of_docs)\n",
    "                plt.ylabel('Hypervolume')\n",
    "                y = []\n",
    "\n",
    "                current_pareto_front = []\n",
    "                for i in range(iterations):\n",
    "                    new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "                    if not isinstance(new_inds, (list,)):\n",
    "                        new_inds = [new_inds]\n",
    "                    for j in range(len(new_inds)):\n",
    "                        # new_ind is a list with one element\n",
    "                        new_ind = [el for el in new_inds if el[\"individual\"] == j]\n",
    "                        if len(new_ind) > 1:\n",
    "                            print(\"ERROR: More than one individual with the same number within the same iteration.\")\n",
    "                        # debug_msg = debug_msg \n",
    "                        #   + \"(\" + str(new_ind[0][\"iteration\"]) + \", \" + str(new_ind[0][\"individual\"]) + \")\"\n",
    "                        current_pareto_front.append(new_ind[0])\n",
    "                        current_pareto_front = get_pareto_front(current_pareto_front)\n",
    "                        current_pareto_front_values = [[get_overhead(el), get_routing(el)] \n",
    "                                                       for el in current_pareto_front]\n",
    "                        hv = hyperVolume.compute(current_pareto_front_values)\n",
    "                        y.append(hv)\n",
    "\n",
    "                plt.plot(x,y, color='black', label='Hypervolume')\n",
    "                pylab.legend(loc='best')\n",
    "\n",
    "                # Overhead over fitness evaluations ###############################          \n",
    "                fig, axes = plt.subplots()\n",
    "                fig.suptitle('Evolution of Overhead', fontsize=16)    \n",
    "                plt.xlabel('Fitness Evaluations') \n",
    "                x = range(total_number_of_docs)\n",
    "                plt.ylabel('Overhead')\n",
    "                y = []\n",
    "\n",
    "                min_overhead_over_iterations = []\n",
    "                best_min = sys.float_info.max\n",
    "                for i in range(iterations):\n",
    "                    new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "                    if not isinstance(new_inds, (list,)):\n",
    "                        new_inds = [new_inds]\n",
    "                    for j in range(len(new_inds)):\n",
    "                        # new_ind is a list with one element\n",
    "                        new_ind = [el for el in new_inds if el[\"individual\"] == j]\n",
    "                        if len(new_ind) > 1:\n",
    "                            print(\"ERROR: More than one individual with the same number within the same iteration.\")    \n",
    "\n",
    "                        overhead = get_overhead(new_ind[0])\n",
    "                        y.append(overhead)\n",
    "                        if overhead < best_min:\n",
    "                            best_min = overhead\n",
    "                        min_overhead_over_iterations.append(best_min)\n",
    "\n",
    "                plt.scatter(x,y, marker=\"+\", color='black', label='individual')\n",
    "                plt.scatter(x, min_overhead_over_iterations, s=100, facecolors='none', \n",
    "                            edgecolors='r', label='perato front for overhead')\n",
    "                pylab.legend(loc='best')\n",
    "\n",
    "                # Routing over fitness evaluations ########################################\n",
    "                fig, axes = plt.subplots()\n",
    "                fig.suptitle('Evolution of Routing', fontsize=16)    \n",
    "                plt.xlabel('Fitness Evaluations') \n",
    "                x = range(total_number_of_docs)\n",
    "                plt.ylabel('Routing')\n",
    "                y = []\n",
    "\n",
    "                min_routing_over_iterations = []\n",
    "                best_min = sys.float_info.max\n",
    "                for i in range(iterations):\n",
    "                    new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "                    if not isinstance(new_inds, (list,)):\n",
    "                        new_inds = [new_inds]\n",
    "                    for j in range(len(new_inds)):\n",
    "                        # new_ind is a list with one element\n",
    "                        new_ind = [el for el in new_inds if el[\"individual\"] == j]\n",
    "                        if len(new_ind) > 1:\n",
    "                            print(\"ERROR: More than one individual with the same number within the same iteration.\")    \n",
    "\n",
    "                        routing = get_routing(new_ind[0])\n",
    "                        y.append(routing)\n",
    "                        if routing < best_min:\n",
    "                            best_min = routing\n",
    "                        min_routing_over_iterations.append(best_min)\n",
    "\n",
    "                plt.scatter(x,y, marker=\"+\", color='black', label='individual')\n",
    "                plt.scatter(x, min_routing_over_iterations, s=100, \n",
    "                            facecolors='none', edgecolors='r', label='perato front for routing')\n",
    "                pylab.legend(loc='best')\n",
    "\n",
    "\n",
    "                # print all individuals and pareto front ##############################\n",
    "                fig, axes = plt.subplots()\n",
    "                # axes.grid(True)\n",
    "                fig.suptitle('All individuals and the pareto front', fontsize=16)\n",
    "                overheads = [get_overhead(el) for el in all_individuals]\n",
    "                routings = [get_routing(el) for el in all_individuals] \n",
    "\n",
    "                plt.ylabel('Routing')\n",
    "                plt.xlabel('Overhead')\n",
    "                plt.scatter(overheads, routings, marker=\"+\", color='black', label='Individual')\n",
    "                p_front_overheads = [get_overhead(el) for el in pareto_front_of_run]\n",
    "                p_front_routings = [get_routing(el) for el in pareto_front_of_run] \n",
    "                if len(pareto_front_of_run) > 1:\n",
    "                    plt.plot(p_front_overheads, p_front_routings, label=\"Pareto Front\")\n",
    "                else:\n",
    "                    plt.scatter(p_front_avg_o, p_front_avg_p, label=\"Pareto Front\")\n",
    "                pylab.legend(loc='best')\n",
    "                #for i,j in zip(avg_o,avg_p):\n",
    "                #    axes.annotate(str(i)+\", \"+str(j),xy=(i,j))\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "    return pareto_fronts_of_all_runs\n",
    "\n",
    "\n",
    "# analyze and plot data\n",
    "\n",
    "large_pfronts = analyze_and_plot(large_runs, large_run_inds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the hypervolume and objectives over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations considered: 100\n",
      "Average Overhead (Best of each run) | Median Overhead (Best of each run) | Average Routing (Best of each run) | Median Routing (Best of each run) |Average Hypervolume | Median Hypervolume\n",
      "Hypervolume [183.76384325222881, 186.14059115144792]\n",
      "Hypervolume [183.76384325222881, 186.14059115144792]\n",
      "Overheads / Routings [1.6165508617445932, 1.6068746987602869] / [1.0, 1.0]\n",
      "Overheads / Routings [1.6165508617445932, 1.6068746987602869] / [1.0, 1.0]\n",
      "NSGA-II (2 runs):\t1.61171278025\t| 1.61171278025\t| 1.0\t| 1.0\t| 184.952217202\t|184.952217202\t| \n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "reference_point = [2.2170968676925815, 311.0] # [worst_overhead, worst_routing]\n",
    "hyperVolume = HyperVolume(reference_point)\n",
    "\n",
    "'''\n",
    "Computes the hypervolumes for all pareto fronts\n",
    "'''\n",
    "def compute_hvs(pfronts):\n",
    "    hvs = []\n",
    "    for pfront in pfronts:\n",
    "        pfront_values = [[get_overhead(el), get_routing(el)] for el in pfront]\n",
    "        hv = hyperVolume.compute(pfront_values)\n",
    "        hvs.append(hv)       \n",
    "    return hvs\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the average hypervolume for all pareto fronts\n",
    "'''\n",
    "def compute_avg_hv(pfronts):\n",
    "    hvs = compute_hvs(pfronts)      \n",
    "    print \"Hypervolume \" + str(hvs)\n",
    "    return np.mean(hvs)\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the median hypervolume for all pareto fronts\n",
    "'''\n",
    "def compute_median_hv(pfronts, plotting=False):\n",
    "    hvs = compute_hvs(pfronts)       \n",
    "    print \"Hypervolume \" + str(hvs)\n",
    "    return np.median(hvs)\n",
    "\n",
    "\n",
    "'''\n",
    "Computes the average of the overhead and routing over all pareto fronts of the all runs\n",
    "'''\n",
    "def compute_avg_objectives(pfronts):\n",
    "    overheads, routings = get_objectives_for_each_pfront(pfronts)\n",
    "    print \"Overheads / Routings \" + str(overheads) + \" / \" + str(routings)\n",
    "    return np.mean(overheads), np.mean(routings)\n",
    "\n",
    "'''\n",
    "Computes the median of the overhead and routing over all pareto fronts of the all runs\n",
    "'''\n",
    "def compute_median_objectives(pfronts):\n",
    "    overheads, routings = get_objectives_for_each_pfront(pfronts)\n",
    "    print \"Overheads / Routings \" + str(overheads) + \" / \" + str(routings)\n",
    "    return np.median(overheads), np.median(routings)\n",
    "\n",
    "\n",
    "def get_objectives_for_each_pfront(pfronts, plotting=False):\n",
    "    overheads = []\n",
    "    routings = []\n",
    "    # for each run/seed\n",
    "    \n",
    "    for pfront in pfronts:\n",
    "        overheads_single_run = [get_overhead(el) for el in pfront]\n",
    "        overheads.append(np.min(overheads_single_run))\n",
    "        routings_single_run = [get_routing(el) for el in pfront]\n",
    "        routings.append(np.min(routings_single_run))\n",
    "    \n",
    "    return overheads, routings\n",
    "\n",
    "\n",
    "'''\n",
    "List of lists, one for each run containing how the hypervolume evolves with each fitness evaluation.\n",
    "'''\n",
    "def compute_hv_over_evals(rtx_runs, run_to_all_individuals, opt_method):\n",
    "    # set iterations\n",
    "    set_iterations(opt_method)\n",
    "    \n",
    "    hv_series_of_all_runs = []\n",
    "    for rtx_run in rtx_runs:\n",
    "        rtx_run_id = rtx_run[\"id\"]\n",
    "        # get all individuals of the run\n",
    "        all_individuals = run_to_all_individuals.get(rtx_run_id, None)\n",
    "        if all_individuals is None:\n",
    "            # print(\"No documents for run \" + str(rtx_run_id))\n",
    "            break\n",
    "       \n",
    "        # debug_msg = \"\"\n",
    "        hv_series = []          \n",
    "        current_pareto_front = []\n",
    "        for i in range(iterations):\n",
    "            new_inds = [el for el in all_individuals if el[\"iteration\"] == i]\n",
    "            if not isinstance(new_inds, (list,)):\n",
    "                new_inds = [new_inds]\n",
    "            for j in range(len(new_inds)):\n",
    "                # new_ind is a list with one element\n",
    "                new_ind = [el for el in new_inds if el[\"individual\"] == j]\n",
    "                if len(new_ind) > 1:\n",
    "                    print(\"ERROR: More than one individual with the same number within the same iteration.\")\n",
    "                # debug_msg = debug_msg \n",
    "                #   + \"(\" + str(new_ind[0][\"iteration\"]) + \", \" + str(new_ind[0][\"individual\"]) + \")\"\n",
    "                current_pareto_front.append(new_ind[0])\n",
    "                current_pareto_front = get_pareto_front(current_pareto_front)\n",
    "                current_pareto_front_values = [[get_overhead(el), get_routing(el)] \n",
    "                                               for el in current_pareto_front]\n",
    "                hv = hyperVolume.compute(current_pareto_front_values)\n",
    "                hv_series.append(hv)\n",
    "        # print(debug_msg)\n",
    "        hv_series_of_all_runs.append(hv_series)\n",
    "    return hv_series_of_all_runs\n",
    "    \n",
    "\n",
    "'''\n",
    "Plots the evolution of the hypervolume of the methods over fitness evaluations. \n",
    "The hypervolume plotted is the mean hypervolume over the runs for each method.\n",
    "'''\n",
    "def plot_hypervolume_evolution(random_rtx_runs, random_run_to_all_individuals,\n",
    "                               nsga2_rtx_runs, nsga2_run_to_all_individuals,\n",
    "                               novelty_rtx_runs, novelty_run_to_all_individuals,\n",
    "                               mlr_rtx_runs, mlr_run_to_all_individuals, cars_number):\n",
    "    methods = [\"BOGP\", \"NSGA-II\", \"Novelty Search\", \"Random\"]\n",
    "    linestyles = [':', '-', '-.', '--']\n",
    "    \n",
    "    mlr_hv_series = compute_hv_over_evals(mlr_rtx_runs, mlr_run_to_all_individuals, methods[0])\n",
    "    nsga2_hv_series = compute_hv_over_evals(nsga2_rtx_runs, nsga2_run_to_all_individuals, methods[1])\n",
    "    novelty_hv_series = compute_hv_over_evals(novelty_rtx_runs, novelty_run_to_all_individuals, methods[2])\n",
    "    random_hv_series = compute_hv_over_evals(random_rtx_runs, random_run_to_all_individuals, methods[3])\n",
    "    \n",
    "    all_hv_series = [mlr_hv_series, nsga2_hv_series, novelty_hv_series, random_hv_series]\n",
    "    \n",
    "    fig, axes = plt.subplots()\n",
    "    # fig.suptitle(\"Evolution of the Mean Hypervolume (\" + str(cars_number) + \" cars)\", fontsize=16)    \n",
    "    plt.ylabel('Mean Hypervolume')\n",
    "    plt.xlabel('Fitness Evaluations')\n",
    "    \n",
    "    for i in range(len(methods)):\n",
    "        method = methods[i]\n",
    "        hv_series = all_hv_series[i]\n",
    "        a = np.array(hv_series)   \n",
    "        plot_data = np.mean(a, axis=0)\n",
    "        print(method + \" - final mean hv: \" + str(plot_data[len(plot_data)-1]))\n",
    "        plt.plot(range(len(plot_data)), plot_data, color='black', linestyle=linestyles[i], label=method)\n",
    "     \n",
    "    pylab.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_hypervolume_boxplots(random_pfronts, nsga2_pfronts, novelty_pfronts, mlr_pfronts, cars_number):\n",
    "    hvs_random = compute_hvs(random_pfronts)\n",
    "    hvs_nsga2 = compute_hvs(nsga2_pfronts)\n",
    "    hvs_novelty = compute_hvs(novelty_pfronts)\n",
    "    hvs_mlr = compute_hvs(mlr_pfronts)\n",
    "\n",
    "    hvs = [hvs_mlr, hvs_nsga2, hvs_novelty, hvs_random]\n",
    "    hvs_names = [\"BOGP\", \"NSGA-II\", \"Novelty S.\", \"Random\"]\n",
    "    hvs_labels = range(1,5)\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    # plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(hvs, 0, '', positions=hvs_labels)\n",
    "    for i in range(len(hvs)):\n",
    "        ax.plot(hvs_labels[i], np.mean(hvs[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(hvs_labels, hvs_names) \n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.show() \n",
    "    \n",
    "    # statistical tests\n",
    "    run_ttest(hvs, hvs_names)\n",
    "    \n",
    "    # distributions\n",
    "    for i in range(len(hvs)):\n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(hvs[i], bins=30)  \n",
    "        plt.title(str(hvs_names[i]) + \" (\" + str(cars_number) + \" cars)\")\n",
    "        plt.ylabel('frequency')\n",
    "        plt.xlabel('hypervolume')\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "def plot_objectives_boxplots(random_pfronts, nsga2_pfronts, novelty_pfronts, mlr_pfronts, cars_number):\n",
    "    overheads_random, routings_random = get_objectives_for_each_pfront(random_pfronts) \n",
    "    overheads_nsga2, routings_nsga2 = get_objectives_for_each_pfront(nsga2_pfronts) \n",
    "    overheads_novelty, routings_novelty = get_objectives_for_each_pfront(novelty_pfronts)  \n",
    "    overheads_mlr, routings_mlr = get_objectives_for_each_pfront(mlr_pfronts)\n",
    "        \n",
    "    overheads = [overheads_mlr, overheads_nsga2, overheads_novelty, overheads_random]\n",
    "    routings  = [routings_mlr, routings_nsga2, routings_novelty, routings_random]\n",
    "    names = [\"BOGP\", \"NSGA-II\", \"Novelty S.\", \"Random\"]\n",
    "    labels = range(1,5)\n",
    "    \n",
    "    # Trip overhead\n",
    "    fig,ax = plt.subplots()\n",
    "    # plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(overheads, 0, '', positions=labels)\n",
    "    for i in range(len(overheads)):\n",
    "        ax.plot(labels[i], np.mean(overheads[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(labels, names) \n",
    "    plt.ylabel('Trip Overhead')\n",
    "    plt.show()\n",
    "    \n",
    "    # statistical test #############\n",
    "    print(\"Trip Overhead:\")\n",
    "    run_ttest(overheads, names)\n",
    "    \n",
    "    # distributions\n",
    "    for i in range(len(overheads)):\n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(overheads[i], bins=30)  \n",
    "        plt.title(\"Distribution: \" + str(names[i]) + \" (\" + str(cars_number) + \" cars)\")\n",
    "        plt.ylabel('frequency')\n",
    "        plt.xlabel('trip overhead')\n",
    "    plt.show()    \n",
    "    \n",
    "    # Routing Cost\n",
    "    fig,ax = plt.subplots()\n",
    "    # plt.title(str(cars_number) + \" cars\")\n",
    "    ax.boxplot(routings, 0, '', positions=labels)\n",
    "    for i in range(len(routings)):\n",
    "        ax.plot(labels[i], np.mean(routings[i]), \".\", label='mean', color='black', linestyle=':')\n",
    "    plt.xticks(labels, names) \n",
    "    plt.ylabel('Routing Cost')\n",
    "    plt.show() \n",
    "        \n",
    "    # statistical test #############\n",
    "    print(\"Routing Cost:\")\n",
    "    run_ttest(routings, names)\n",
    "    \n",
    "     # distributions\n",
    "    for i in range(len(routings)):\n",
    "        fig,ax = plt.subplots()\n",
    "        plt.hist(routings[i], bins=30)  \n",
    "        plt.title(\"Distribution: \" + str(names[i]) + \" (\" + str(cars_number) + \" cars)\")\n",
    "        plt.ylabel('frequency')\n",
    "        plt.xlabel('routing')\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "def run_ttest(dataXXX, names):\n",
    "    alpha = 0.05\n",
    "    for i in range(len(dataXXX)):\n",
    "        data_first = dataXXX[i]\n",
    "        name_first = names[i]\n",
    "        for j in range(len(names)):\n",
    "            if j == i:\n",
    "                break\n",
    "            data_second = dataXXX[j]\n",
    "            name_second = names[j]\n",
    "            statistic, pvalue = stats.ttest_ind(data_first, data_second, equal_var = False)\n",
    "            statistic2, pvalue2 = stats.wilcoxon(data_first, data_second)\n",
    "            \n",
    "            different_averages = bool(pvalue <= alpha)\n",
    "            is_is_not = \"\\tis\\t\" if different_averages else \"\\tis not\\t\"\n",
    "            print(name_first + is_is_not \n",
    "                  + \" statistically significantly different than \"+ name_second + \" (ttest)\")\n",
    "            \n",
    "            different_averages2 = bool(pvalue2 <= alpha)\n",
    "            is_is_not2 = \"\\tis\\t\" if different_averages2 else \"\\tis not\\t\"\n",
    "            print(name_first + is_is_not2 \n",
    "                  + \" statistically significantly different than \"+ name_second + \" (wilcoxon)\")\n",
    "\n",
    "\n",
    "            \n",
    "def check_avg(pfronts, name):\n",
    "    avg_hv = compute_avg_hv(pfronts)\n",
    "    median_hv = compute_median_hv(pfronts)\n",
    "    \n",
    "    avg_best_objectives = compute_avg_objectives(pfronts)\n",
    "    avg_best_overhead = avg_best_objectives[0]\n",
    "    avg_best_routing = avg_best_objectives[1]\n",
    "    \n",
    "    med_best_objectives = compute_median_objectives(pfronts)\n",
    "    med_best_overhead = med_best_objectives[0]\n",
    "    med_best_routing = med_best_objectives[1]\n",
    "    \n",
    "    tt = \"\\t\\t\" if name == \"BOGP\" else \"\\t\"\n",
    "        \n",
    "        \n",
    "    print(name + \" (\"+str(len(pfronts))+\" runs):\" + tt\n",
    "          + str(avg_best_overhead) + \"\\t| \" + str(med_best_overhead) + \"\\t| \" \n",
    "          + str(avg_best_routing) + \"\\t| \" + str(med_best_routing) + \"\\t| \" \n",
    "          + str(avg_hv) + \"\\t|\" + str(median_hv) + \"\\t| \")\n",
    "    \n",
    "\n",
    "    \n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "print(\"Iterations considered: \" + str(iterations))\n",
    "print(\"Average Overhead (Best of each run) | Median Overhead (Best of each run)\" \n",
    "      +\" | Average Routing (Best of each run) | Median Routing (Best of each run)\" \n",
    "      +\" |Average Hypervolume | Median Hypervolume\" )\n",
    "\n",
    "check_avg(large_pfronts, \"NSGA-II\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
